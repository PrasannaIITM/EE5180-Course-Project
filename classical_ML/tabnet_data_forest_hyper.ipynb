{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "60-_obGOXJMD"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wget\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC8v45OqWWGT",
    "outputId": "187937a7-53ac-4706-e29b-775e1cd7259f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost_info\t\t\t   tabnet_data_forest_hyper.ipynb\r\n",
      "cat_boost_preds.csv\t\t   test_shrutime.csv\r\n",
      "data\t\t\t\t   train_shrutime.csv\r\n",
      "forest_example_classical_ML.ipynb  Untitled.ipynb\r\n",
      "shrutime_classical_ML.ipynb\t   xgboost_preds.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GKAb9fN2Wjy_"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/train_forest_cover.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "KjSlHFDktk7e",
    "outputId": "2c522556-271b-4667-fe07-0fbed987bf49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Covertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2631</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>226</td>\n",
       "      <td>234</td>\n",
       "      <td>143</td>\n",
       "      <td>1761</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3287</td>\n",
       "      <td>107</td>\n",
       "      <td>25</td>\n",
       "      <td>459</td>\n",
       "      <td>130</td>\n",
       "      <td>1144</td>\n",
       "      <td>253</td>\n",
       "      <td>201</td>\n",
       "      <td>61</td>\n",
       "      <td>1099</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2130</td>\n",
       "      <td>144</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1167</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>129</td>\n",
       "      <td>1423</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3022</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>402</td>\n",
       "      <td>77</td>\n",
       "      <td>4245</td>\n",
       "      <td>232</td>\n",
       "      <td>217</td>\n",
       "      <td>115</td>\n",
       "      <td>1782</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3190</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>1634</td>\n",
       "      <td>230</td>\n",
       "      <td>209</td>\n",
       "      <td>108</td>\n",
       "      <td>2301</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2631     104      4                                 0   \n",
       "1       3287     107     25                               459   \n",
       "2       2130     144     12                                30   \n",
       "3       3022      69     12                               402   \n",
       "4       3190      60     14                                90   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              806   \n",
       "1                             130                             1144   \n",
       "2                               2                             1167   \n",
       "3                              77                             4245   \n",
       "4                              29                             1634   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            226             234            143   \n",
       "1            253             201             61   \n",
       "2            237             238            129   \n",
       "3            232             217            115   \n",
       "4            230             209            108   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                1761  ...            0            0   \n",
       "1                                1099  ...            0            0   \n",
       "2                                1423  ...            0            0   \n",
       "3                                1782  ...            0            0   \n",
       "4                                2301  ...            0            1   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Covertype  \n",
       "0            0            0          2  \n",
       "1            0            1          7  \n",
       "2            0            0          4  \n",
       "3            0            0          2  \n",
       "4            0            0          1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OcUWpIquWsCC"
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('data/test_forest_cover.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "JXEB5noUXAzv",
    "outputId": "3d3ca9d8-c850-496e-f45d-bb16a33c8ee2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Covertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2991</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>503</td>\n",
       "      <td>72</td>\n",
       "      <td>5124</td>\n",
       "      <td>233</td>\n",
       "      <td>225</td>\n",
       "      <td>124</td>\n",
       "      <td>5501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3360</td>\n",
       "      <td>185</td>\n",
       "      <td>13</td>\n",
       "      <td>566</td>\n",
       "      <td>102</td>\n",
       "      <td>4468</td>\n",
       "      <td>222</td>\n",
       "      <td>249</td>\n",
       "      <td>158</td>\n",
       "      <td>2561</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3286</td>\n",
       "      <td>352</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>4097</td>\n",
       "      <td>206</td>\n",
       "      <td>226</td>\n",
       "      <td>158</td>\n",
       "      <td>1635</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2861</td>\n",
       "      <td>103</td>\n",
       "      <td>13</td>\n",
       "      <td>607</td>\n",
       "      <td>29</td>\n",
       "      <td>450</td>\n",
       "      <td>242</td>\n",
       "      <td>222</td>\n",
       "      <td>108</td>\n",
       "      <td>1170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2834</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "      <td>13</td>\n",
       "      <td>1184</td>\n",
       "      <td>236</td>\n",
       "      <td>227</td>\n",
       "      <td>122</td>\n",
       "      <td>1832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2991      85      9                               503   \n",
       "1       3360     185     13                               566   \n",
       "2       3286     352      8                                90   \n",
       "3       2861     103     13                               607   \n",
       "4       2834      97      9                               108   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                              72                             5124   \n",
       "1                             102                             4468   \n",
       "2                               6                             4097   \n",
       "3                              29                              450   \n",
       "4                              13                             1184   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            233             225            124   \n",
       "1            222             249            158   \n",
       "2            206             226            158   \n",
       "3            242             222            108   \n",
       "4            236             227            122   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                5501  ...            0            0   \n",
       "1                                2561  ...            0            1   \n",
       "2                                1635  ...            0            0   \n",
       "3                                1170  ...            0            0   \n",
       "4                                1832  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Covertype  \n",
       "0            0            0          2  \n",
       "1            0            0          7  \n",
       "2            0            0          1  \n",
       "3            0            0          2  \n",
       "4            0            0          2  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fekRUXYBXCV3"
   },
   "outputs": [],
   "source": [
    "X=df.drop(labels=['Covertype'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CtNZm5x9XhQv"
   },
   "outputs": [],
   "source": [
    "y=df['Covertype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2K8B6-LbXoj8"
   },
   "outputs": [],
   "source": [
    "x_test=test_df.drop(labels=['Covertype'],axis=1)\n",
    "y_test=test_df['Covertype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_CPmThs_XxVF"
   },
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid=train_test_split(X,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRRrz8z3zAnj",
    "outputId": "dfb460c2-42ab-4d36-e484-cd6296446211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (3.1.1)\n",
      "Requirement already satisfied: scipy>1.4 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from pytorch-tabnet) (1.6.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from pytorch-tabnet) (4.60.0)\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from pytorch-tabnet) (1.7.1+cu101)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from pytorch-tabnet) (0.24.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from pytorch-tabnet) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bCdVg4CXzQIN"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9RB96YELzf9G"
   },
   "outputs": [],
   "source": [
    "# train=pd.read_csv('/content/data/train_covertype.csv')\n",
    "# test=pd.read_csv('/content/data/test_covertype.csv')\n",
    "# val=pd.read_csv('/content/data/val_covertype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ftBGh_70f0f",
    "outputId": "5da9d694-c04b-46e9-9bc0-f85f424aa890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fast_ml in /home/neham/anaconda3/envs/seathru/lib/python3.9/site-packages (3.68)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fast_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TBFKCB5t9Se",
    "outputId": "1c78b95a-8dab-484f-affd-cdd681d7b232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371847, 54)\n",
      "(371847,)\n",
      "(92962, 54)\n",
      "(92962,)\n",
      "(116203, 54)\n",
      "(116203,)\n",
      "(464809, 55)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "#y_train = np.expand_dims(y_train, axis=1)\n",
    "#y_train = convert_to_one_hot(y_train)\n",
    "\n",
    "\n",
    "x_valid = x_valid.to_numpy()\n",
    "y_valid = y_valid.to_numpy()\n",
    "#y_valid = np.expand_dims(y_valid, axis=1)\n",
    "#y_valid = convert_to_one_hot(y_valid)\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "#y_test = np.expand_dims(y_test, axis=1)\n",
    "#y_test = convert_to_one_hot(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "# y = df[df.columns[-1]]\n",
    "# y = y.to_numpy()\n",
    "target_cols = [\"Covertype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4cQIPit30rxc"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ehT6opIV1Hcp"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LFYiZ_cP1Tv3"
   },
   "outputs": [],
   "source": [
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "omqi0I5u1Uvc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
    "from hyperopt.pyll.base import scope\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tsONlCvzXTR8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0iNA7AAVqTE",
    "outputId": "ffb451b9-633b-4b73-b755-cc0281e1595e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371847, 54)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7yrQ0_k5IBnf"
   },
   "outputs": [],
   "source": [
    "def tb_ll_cv(space):\n",
    "  #print(\"hello\")\n",
    "  model=TabNetClassifier(n_a=int(space['n_a']), n_d=int(space['n_a']), n_steps=int(space['n_steps']), momentum=space['momentum'], gamma=space['gamma'], optimizer_params=dict(lr=space['lr']), device_name='cuda')\n",
    "  model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], batch_size=int(space['batch_size']),max_epochs=40,eval_metric=['logloss'])\n",
    "  print(model.history[\"val_0_logloss\"])\n",
    "  return min(model.history[\"val_0_logloss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JijpC5Xt1Yib"
   },
   "outputs": [],
   "source": [
    "reg_params = {'n_a': hp.quniform('feature_dim', 20, 60, 1),'n_steps': hp.quniform('n_steps', 1, 8, 1),'momentum': hp.uniform('momentum', np.exp(-5), np.exp(-1)),'gamma': hp.uniform('relaxation_factor', 0.3, 2),\n",
    "    'batch_size': hp.choice('batch_size',[512, 1024, 2048, 4096, 8192]), 'lr':hp.loguniform('learning_rate', -5, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MF2xcftPs66",
    "outputId": "1d316a6d-f15d-4cbd-d950-ca225d1aa676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda                                    \n",
      "epoch 0  | loss: 1.40517 | val_0_logloss: 1.49424 |  0:00:11s\n",
      "epoch 1  | loss: 0.80838 | val_0_logloss: 8.64187 |  0:00:23s\n",
      "epoch 2  | loss: 0.74726 | val_0_logloss: 6.43113 |  0:00:34s\n",
      "epoch 3  | loss: 0.73273 | val_0_logloss: 2.77452 |  0:00:46s\n",
      "epoch 4  | loss: 0.718   | val_0_logloss: 1.43591 |  0:00:59s\n",
      "epoch 5  | loss: 0.7324  | val_0_logloss: 1.16142 |  0:01:11s\n",
      "epoch 6  | loss: 0.74161 | val_0_logloss: 0.83794 |  0:01:23s\n",
      "epoch 7  | loss: 0.72721 | val_0_logloss: 0.7773  |  0:01:36s\n",
      "epoch 8  | loss: 0.72202 | val_0_logloss: 0.72735 |  0:01:48s\n",
      "epoch 9  | loss: 0.72161 | val_0_logloss: 0.72685 |  0:02:00s\n",
      "epoch 10 | loss: 0.71795 | val_0_logloss: 0.70177 |  0:02:12s\n",
      "epoch 11 | loss: 0.71775 | val_0_logloss: 0.72614 |  0:02:24s\n",
      "epoch 12 | loss: 0.73681 | val_0_logloss: 0.72397 |  0:02:36s\n",
      "epoch 13 | loss: 0.72443 | val_0_logloss: 0.71865 |  0:02:47s\n",
      "epoch 14 | loss: 0.73356 | val_0_logloss: 0.73256 |  0:02:59s\n",
      "epoch 15 | loss: 0.72618 | val_0_logloss: 0.72048 |  0:03:10s\n",
      "epoch 16 | loss: 0.71918 | val_0_logloss: 0.72382 |  0:03:21s\n",
      "epoch 17 | loss: 0.71965 | val_0_logloss: 0.71259 |  0:03:33s\n",
      "epoch 18 | loss: 0.71652 | val_0_logloss: 0.71481 |  0:03:45s\n",
      "epoch 19 | loss: 0.7158  | val_0_logloss: 0.70736 |  0:03:56s\n",
      "epoch 20 | loss: 0.71634 | val_0_logloss: 0.70792 |  0:04:08s\n",
      "                                                      \n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_logloss = 0.70177\n",
      "Best weights from best epoch are automatically used!  \n",
      "[1.4942355511156897, 8.641865229642056, 6.431125831409321, 2.7745189066000604, 1.435914925009715, 1.1614210931362032, 0.8379354148122813, 0.7772974487092262, 0.7273463891056806, 0.7268484706321057, 0.701770766724417, 0.726137896147639, 0.7239715902984369, 0.7186531560353917, 0.7325626613324572, 0.720484983823136, 0.7238248243007533, 0.712590008576769, 0.7148116443070016, 0.7073629719420654, 0.7079212111226875]\n",
      "Device used : cuda                                                              \n",
      "epoch 0  | loss: 0.7341  | val_0_logloss: 11.17443|  0:00:16s                   \n",
      "epoch 1  | loss: 0.58151 | val_0_logloss: 3.27678 |  0:00:31s                   \n",
      "epoch 2  | loss: 0.52889 | val_0_logloss: 1.05516 |  0:00:48s                   \n",
      "epoch 3  | loss: 0.48743 | val_0_logloss: 0.58856 |  0:01:04s                   \n",
      "epoch 4  | loss: 0.45986 | val_0_logloss: 0.49076 |  0:01:21s                   \n",
      "epoch 5  | loss: 0.43847 | val_0_logloss: 0.40625 |  0:01:37s                   \n",
      "epoch 6  | loss: 0.41956 | val_0_logloss: 0.38273 |  0:01:54s                   \n",
      "epoch 7  | loss: 0.39871 | val_0_logloss: 0.36213 |  0:02:10s                   \n",
      "epoch 8  | loss: 0.38005 | val_0_logloss: 0.34447 |  0:02:27s                   \n",
      "epoch 9  | loss: 0.3691  | val_0_logloss: 0.34806 |  0:02:43s                   \n",
      "epoch 10 | loss: 0.53915 | val_0_logloss: 0.50124 |  0:02:59s                   \n",
      "epoch 11 | loss: 0.52459 | val_0_logloss: 0.48481 |  0:03:16s                   \n",
      "epoch 12 | loss: 0.49574 | val_0_logloss: 0.44994 |  0:03:31s                   \n",
      "epoch 13 | loss: 0.49531 | val_0_logloss: 0.48065 |  0:03:48s                   \n",
      "epoch 14 | loss: 0.51344 | val_0_logloss: 0.4504  |  0:04:03s                   \n",
      "epoch 15 | loss: 0.49743 | val_0_logloss: 0.44885 |  0:04:18s                   \n",
      "epoch 16 | loss: 0.48334 | val_0_logloss: 0.45014 |  0:04:34s                   \n",
      "epoch 17 | loss: 0.45788 | val_0_logloss: 0.41757 |  0:04:51s                   \n",
      "epoch 18 | loss: 0.43903 | val_0_logloss: 0.39434 |  0:05:07s                   \n",
      "                                                                                \n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_logloss = 0.34447\n",
      "Best weights from best epoch are automatically used!                            \n",
      "[11.174425273579422, 3.2767756910751373, 1.055156202876834, 0.5885597073340787, 0.4907572980492442, 0.40625259154124355, 0.38272886430518005, 0.3621258594148884, 0.34446965845008215, 0.34805872016259953, 0.5012367603713955, 0.4848077032880176, 0.44994009433280213, 0.48065259129095933, 0.4503955239220452, 0.44885147295680106, 0.4501420575969238, 0.4175679453909088, 0.39434437015049545]\n",
      "Device used : cuda                                                                  \n",
      "epoch 0  | loss: 1.14433 | val_0_logloss: 14.88132|  0:00:27s                       \n",
      "epoch 1  | loss: 0.72578 | val_0_logloss: 2.88564 |  0:00:54s                       \n",
      "epoch 2  | loss: 0.72977 | val_0_logloss: 0.98786 |  0:01:21s                       \n",
      "epoch 3  | loss: 0.72934 | val_0_logloss: 0.76772 |  0:01:47s                       \n",
      "epoch 4  | loss: 0.71776 | val_0_logloss: 0.71751 |  0:02:13s                       \n",
      "epoch 5  | loss: 0.72548 | val_0_logloss: 0.7513  |  0:02:38s                       \n",
      "epoch 6  | loss: 0.72266 | val_0_logloss: 0.71836 |  0:03:04s                       \n",
      "epoch 7  | loss: 0.71933 | val_0_logloss: 0.72441 |  0:03:31s                       \n",
      "epoch 8  | loss: 0.71213 | val_0_logloss: 0.71209 |  0:03:57s                       \n",
      "epoch 9  | loss: 0.71128 | val_0_logloss: 0.71781 |  0:04:25s                       \n",
      "epoch 10 | loss: 0.71125 | val_0_logloss: 0.74617 |  0:04:52s                       \n",
      "epoch 11 | loss: 0.70947 | val_0_logloss: 0.77219 |  0:05:18s                       \n",
      "epoch 12 | loss: 0.7602  | val_0_logloss: 0.75078 |  0:05:44s                       \n",
      "epoch 13 | loss: 0.74954 | val_0_logloss: 0.72737 |  0:06:10s                       \n",
      "epoch 14 | loss: 0.73799 | val_0_logloss: 0.7281  |  0:06:37s                       \n",
      "epoch 15 | loss: 0.73944 | val_0_logloss: 0.73463 |  0:07:03s                       \n",
      "epoch 16 | loss: 0.73404 | val_0_logloss: 0.73702 |  0:07:29s                       \n",
      "epoch 17 | loss: 0.72161 | val_0_logloss: 0.71469 |  0:07:55s                       \n",
      "epoch 18 | loss: 0.71322 | val_0_logloss: 0.71396 |  0:08:22s                       \n",
      "                                                                                    \n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_logloss = 0.71209\n",
      "Best weights from best epoch are automatically used!                                \n",
      "[14.881315515399763, 2.8856362518857446, 0.9878553677009179, 0.7677159317534301, 0.7175131548927721, 0.7513034510173782, 0.7183577427409338, 0.7244088171316846, 0.712093236744809, 0.717811415601198, 0.7461725239466764, 0.7721926376516209, 0.7507840522118164, 0.7273739794140689, 0.7281002968207987, 0.7346341557696868, 0.7370183003597828, 0.7146924823838785, 0.7139588059524209]\n",
      "Device used : cuda                                                                  \n",
      "epoch 0  | loss: 0.73631 | val_0_logloss: 0.67559 |  0:00:42s                       \n",
      "epoch 1  | loss: 0.65479 | val_0_logloss: 0.63089 |  0:01:22s                       \n",
      "epoch 2  | loss: 0.61971 | val_0_logloss: 0.58789 |  0:02:01s                       \n",
      "epoch 3  | loss: 0.57398 | val_0_logloss: 0.52551 |  0:02:42s                       \n",
      "epoch 4  | loss: 0.51632 | val_0_logloss: 0.47347 |  0:03:24s                       \n",
      "epoch 5  | loss: 0.49144 | val_0_logloss: 0.48448 |  0:04:07s                       \n",
      "epoch 6  | loss: 0.51711 | val_0_logloss: 0.48114 |  0:04:49s                       \n",
      "epoch 7  | loss: 0.46315 | val_0_logloss: 0.40437 |  0:05:31s                       \n",
      "epoch 8  | loss: 0.41513 | val_0_logloss: 0.3901  |  0:06:11s                       \n",
      "epoch 9  | loss: 0.39564 | val_0_logloss: 0.34085 |  0:06:54s                       \n",
      "epoch 10 | loss: 0.37969 | val_0_logloss: 0.33632 |  0:07:37s                       \n",
      "epoch 11 | loss: 0.36494 | val_0_logloss: 0.32019 |  0:08:20s                       \n",
      "epoch 12 | loss: 0.34771 | val_0_logloss: 0.3005  |  0:09:01s                       \n",
      "epoch 13 | loss: 0.3315  | val_0_logloss: 0.29472 |  0:09:42s                       \n",
      "epoch 14 | loss: 0.32677 | val_0_logloss: 0.27981 |  0:10:25s                       \n",
      "epoch 15 | loss: 0.3113  | val_0_logloss: 0.26562 |  0:11:07s                       \n",
      "epoch 16 | loss: 0.30437 | val_0_logloss: 0.26817 |  0:11:49s                       \n",
      "epoch 17 | loss: 0.29748 | val_0_logloss: 0.28702 |  0:12:31s                       \n",
      "epoch 18 | loss: 0.29352 | val_0_logloss: 0.26873 |  0:13:09s                       \n",
      "epoch 19 | loss: 0.29127 | val_0_logloss: 0.25758 |  0:13:52s                       \n",
      "epoch 20 | loss: 0.28504 | val_0_logloss: 0.23981 |  0:14:31s                       \n",
      "epoch 21 | loss: 0.27735 | val_0_logloss: 0.24283 |  0:15:13s                       \n",
      "epoch 22 | loss: 0.28164 | val_0_logloss: 0.24569 |  0:15:55s                       \n",
      "epoch 23 | loss: 0.28276 | val_0_logloss: 0.24312 |  0:16:37s                       \n",
      "epoch 24 | loss: 0.28187 | val_0_logloss: 0.23947 |  0:17:19s                       \n",
      "epoch 25 | loss: 0.27284 | val_0_logloss: 0.22976 |  0:17:58s                       \n",
      "epoch 26 | loss: 0.28209 | val_0_logloss: 0.27818 |  0:18:38s                       \n",
      "epoch 27 | loss: 0.288   | val_0_logloss: 0.24287 |  0:19:19s                       \n",
      "epoch 28 | loss: 0.26735 | val_0_logloss: 0.22159 |  0:20:02s                       \n",
      "epoch 29 | loss: 0.26541 | val_0_logloss: 0.22562 |  0:20:44s                       \n",
      "epoch 30 | loss: 0.26393 | val_0_logloss: 0.22224 |  0:21:27s                       \n",
      "epoch 31 | loss: 0.25967 | val_0_logloss: 0.21736 |  0:22:09s                       \n",
      "epoch 32 | loss: 0.24877 | val_0_logloss: 0.20718 |  0:22:51s                       \n",
      "epoch 33 | loss: 0.2454  | val_0_logloss: 0.20634 |  0:23:33s                       \n",
      "epoch 34 | loss: 0.24163 | val_0_logloss: 0.2095  |  0:24:16s                       \n",
      "epoch 35 | loss: 0.24322 | val_0_logloss: 0.21479 |  0:24:57s                       \n",
      "epoch 36 | loss: 0.23885 | val_0_logloss: 0.20447 |  0:25:33s                       \n",
      "epoch 37 | loss: 0.23734 | val_0_logloss: 0.2044  |  0:26:14s                       \n",
      "epoch 38 | loss: 0.23462 | val_0_logloss: 0.19197 |  0:26:57s                       \n",
      "epoch 39 | loss: 0.23319 | val_0_logloss: 0.20589 |  0:27:36s                       \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 38 and best_val_0_logloss = 0.19197\n",
      "Best weights from best epoch are automatically used!                                \n",
      "[0.6755934244078373, 0.6308878744988377, 0.5878891336724341, 0.5255093982122295, 0.47347050481950903, 0.4844810994143302, 0.4811436875377073, 0.40437060532430014, 0.3900964152560669, 0.3408518611671597, 0.3363204441309034, 0.3201943560092289, 0.3005000653368293, 0.2947217818728354, 0.27980515882167767, 0.265618348104376, 0.26816825357192353, 0.287018702524262, 0.26872709117406757, 0.257580976923281, 0.23981302857942113, 0.24282754760836872, 0.24569079927319315, 0.2431153932069012, 0.23947397434446252, 0.22976044732919151, 0.27817637696547515, 0.24287199903225587, 0.22158656847128594, 0.22562245498648473, 0.22224205344562292, 0.21736330121240108, 0.20718137880875717, 0.2063373369293083, 0.20949932582533887, 0.2147910746402222, 0.20447005602517085, 0.204396143338839, 0.19197449242830508, 0.2058893364716023]\n",
      "Device used : cuda                                                                  \n",
      "epoch 0  | loss: 0.7206  | val_0_logloss: 1.44755 |  0:00:15s                       \n",
      "epoch 1  | loss: 0.54976 | val_0_logloss: 0.62954 |  0:00:30s                       \n",
      "epoch 2  | loss: 0.47888 | val_0_logloss: 0.43461 |  0:00:45s                       \n",
      "epoch 3  | loss: 0.42923 | val_0_logloss: 0.37827 |  0:01:00s                       \n",
      "epoch 4  | loss: 0.3881  | val_0_logloss: 0.34646 |  0:01:15s                       \n",
      "epoch 5  | loss: 0.3599  | val_0_logloss: 0.32503 |  0:01:30s                       \n",
      "epoch 6  | loss: 0.33709 | val_0_logloss: 0.31057 |  0:01:45s                       \n",
      "epoch 7  | loss: 0.32054 | val_0_logloss: 0.28365 |  0:01:59s                       \n",
      "epoch 8  | loss: 0.3058  | val_0_logloss: 0.27032 |  0:02:14s                       \n",
      "epoch 9  | loss: 0.28924 | val_0_logloss: 0.26184 |  0:02:29s                       \n",
      "epoch 10 | loss: 0.28428 | val_0_logloss: 0.24553 |  0:02:44s                       \n",
      "epoch 11 | loss: 0.27418 | val_0_logloss: 0.25463 |  0:02:59s                       \n",
      "epoch 12 | loss: 0.26724 | val_0_logloss: 0.23546 |  0:03:13s                       \n",
      "epoch 13 | loss: 0.25772 | val_0_logloss: 0.23191 |  0:03:28s                       \n",
      "epoch 14 | loss: 0.25169 | val_0_logloss: 0.22678 |  0:03:42s                       \n",
      "epoch 15 | loss: 0.24873 | val_0_logloss: 0.22497 |  0:03:57s                       \n",
      "epoch 16 | loss: 0.24224 | val_0_logloss: 0.21799 |  0:04:11s                       \n",
      "epoch 17 | loss: 0.23777 | val_0_logloss: 0.21083 |  0:04:26s                       \n",
      "epoch 18 | loss: 0.23364 | val_0_logloss: 0.2055  |  0:04:41s                       \n",
      "epoch 19 | loss: 0.23031 | val_0_logloss: 0.21229 |  0:04:55s                       \n",
      "epoch 20 | loss: 0.22749 | val_0_logloss: 0.19984 |  0:05:10s                       \n",
      "epoch 21 | loss: 0.22529 | val_0_logloss: 0.19451 |  0:05:24s                       \n",
      "epoch 22 | loss: 0.22112 | val_0_logloss: 0.20933 |  0:05:39s                       \n",
      "epoch 23 | loss: 0.2218  | val_0_logloss: 0.19946 |  0:05:53s                       \n",
      "epoch 24 | loss: 0.21848 | val_0_logloss: 0.19382 |  0:06:08s                       \n",
      "epoch 25 | loss: 0.21543 | val_0_logloss: 0.18569 |  0:06:22s                       \n",
      "epoch 26 | loss: 0.21353 | val_0_logloss: 0.19234 |  0:06:37s                       \n",
      "epoch 27 | loss: 0.21155 | val_0_logloss: 0.18455 |  0:06:52s                       \n",
      "epoch 28 | loss: 0.21024 | val_0_logloss: 0.18175 |  0:07:08s                       \n",
      "epoch 29 | loss: 0.20726 | val_0_logloss: 0.18271 |  0:07:23s                       \n",
      "epoch 30 | loss: 0.20557 | val_0_logloss: 0.18454 |  0:07:39s                       \n",
      "epoch 31 | loss: 0.2026  | val_0_logloss: 0.17887 |  0:07:54s                       \n",
      "epoch 32 | loss: 0.20332 | val_0_logloss: 0.17783 |  0:08:08s                       \n",
      "epoch 33 | loss: 0.20102 | val_0_logloss: 0.17505 |  0:08:23s                       \n",
      "epoch 34 | loss: 0.19878 | val_0_logloss: 0.1737  |  0:08:38s                       \n",
      "epoch 35 | loss: 0.19894 | val_0_logloss: 0.17769 |  0:08:51s                       \n",
      "epoch 36 | loss: 0.19724 | val_0_logloss: 0.18245 |  0:09:05s                       \n",
      "epoch 37 | loss: 0.19643 | val_0_logloss: 0.17059 |  0:09:21s                       \n",
      "epoch 38 | loss: 0.19116 | val_0_logloss: 0.17972 |  0:09:36s                       \n",
      "epoch 39 | loss: 0.193   | val_0_logloss: 0.16889 |  0:09:51s                       \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 39 and best_val_0_logloss = 0.16889\n",
      "Best weights from best epoch are automatically used!                                \n",
      "[1.4475496704027146, 0.6295361822894766, 0.434606242515428, 0.3782726890075968, 0.3464647125031276, 0.32503004752974257, 0.31057080012064253, 0.283652872060879, 0.2703207147520595, 0.26183611845378335, 0.24553302203100738, 0.2546274321085132, 0.2354553008548566, 0.2319083581369571, 0.22678370262519162, 0.224973957327775, 0.21799114448149243, 0.2108316571136273, 0.20549826233634474, 0.21229403445189834, 0.1998437385122989, 0.1945111845276382, 0.20932863914435507, 0.1994620795965719, 0.19382451945782248, 0.18569469095444346, 0.19234302936140818, 0.18454601111827582, 0.18174550116184005, 0.18271441398659008, 0.18453614326176787, 0.17887003088907458, 0.1778343373084421, 0.17505273849140812, 0.1737017356965792, 0.1776870702282979, 0.18244891052603518, 0.17058697637578263, 0.17971690681332683, 0.16889440966047728]\n",
      "Device used : cuda                                                                  \n",
      "epoch 0  | loss: 1.72585 | val_0_logloss: 1.40329 |  0:00:19s                       \n",
      "epoch 1  | loss: 1.02733 | val_0_logloss: 1.13348 |  0:00:37s                       \n",
      "epoch 2  | loss: 1.09846 | val_0_logloss: 1.03877 |  0:00:56s                       \n",
      "epoch 3  | loss: 0.98736 | val_0_logloss: 1.01339 |  0:01:14s                       \n",
      "epoch 4  | loss: 1.04592 | val_0_logloss: 1.45263 |  0:01:30s                       \n",
      "epoch 5  | loss: 0.9906  | val_0_logloss: 0.98897 |  0:01:47s                       \n",
      "epoch 6  | loss: 0.98036 | val_0_logloss: 1.02832 |  0:02:07s                       \n",
      "epoch 7  | loss: 0.98044 | val_0_logloss: 1.02858 |  0:02:25s                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8  | loss: 0.98047 | val_0_logloss: 1.03027 |  0:02:44s                       \n",
      "epoch 9  | loss: 0.98003 | val_0_logloss: 1.02797 |  0:03:03s                       \n",
      "epoch 10 | loss: 0.97855 | val_0_logloss: 0.97533 |  0:03:22s                       \n",
      "epoch 11 | loss: 0.97628 | val_0_logloss: 0.97425 |  0:03:42s                       \n",
      "epoch 12 | loss: 0.97429 | val_0_logloss: 0.98205 |  0:04:00s                       \n",
      "epoch 13 | loss: 0.97491 | val_0_logloss: 0.97393 |  0:04:18s                       \n",
      "epoch 14 | loss: 0.97601 | val_0_logloss: 0.97537 |  0:04:38s                         \n",
      "epoch 15 | loss: 0.97763 | val_0_logloss: 0.98312 |  0:04:57s                         \n",
      "epoch 16 | loss: 0.97562 | val_0_logloss: 0.97285 |  0:05:16s                         \n",
      "epoch 17 | loss: 0.97426 | val_0_logloss: 0.97378 |  0:05:36s                         \n",
      "epoch 18 | loss: 0.97517 | val_0_logloss: 0.98077 |  0:05:55s                         \n",
      "epoch 19 | loss: 0.97516 | val_0_logloss: 1.03957 |  0:06:15s                         \n",
      "epoch 20 | loss: 0.97487 | val_0_logloss: 0.9957  |  0:06:33s                         \n",
      "epoch 21 | loss: 0.97451 | val_0_logloss: 0.97652 |  0:06:52s                         \n",
      "epoch 22 | loss: 0.97413 | val_0_logloss: 0.98059 |  0:07:12s                         \n",
      "epoch 23 | loss: 0.97422 | val_0_logloss: 0.97346 |  0:07:29s                         \n",
      "epoch 24 | loss: 0.97543 | val_0_logloss: 0.9796  |  0:07:49s                         \n",
      "epoch 25 | loss: 0.97465 | val_0_logloss: 0.97601 |  0:08:08s                         \n",
      "epoch 26 | loss: 0.9764  | val_0_logloss: 0.97696 |  0:08:28s                         \n",
      "                                                                                      \n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_logloss = 0.97285\n",
      "Best weights from best epoch are automatically used!                                  \n",
      "[1.4032912862007552, 1.1334836048090289, 1.038766434807309, 1.0133871578274958, 1.4526315539218055, 0.9889721811639701, 1.0283225506748648, 1.0285848207031705, 1.0302696323414524, 1.027968191437681, 0.9753305737349344, 0.9742498772876786, 0.9820501013527133, 0.973930489092351, 0.9753740367851241, 0.9831227142025839, 0.9728456705296343, 0.9737799115212425, 0.9807748497080643, 1.039565189719772, 0.9956979929826358, 0.9765173130430485, 0.9805943335508208, 0.9734636623629488, 0.9795977818915795, 0.9760124160182456, 0.9769585347878835]\n",
      "Device used : cuda                                                                    \n",
      "epoch 0  | loss: 1.31652 | val_0_logloss: 4.676   |  0:00:42s                         \n",
      "epoch 1  | loss: 3.43753 | val_0_logloss: 17.71635|  0:01:24s                         \n",
      "epoch 2  | loss: 5.21021 | val_0_logloss: 21.94555|  0:02:04s                         \n",
      "epoch 3  | loss: 21.9659 | val_0_logloss: 4.75582 |  0:02:47s                         \n",
      "epoch 4  | loss: 16.31532| val_0_logloss: 1.20144 |  0:03:29s                         \n",
      "epoch 5  | loss: 1.21606 | val_0_logloss: 1.20585 |  0:04:11s                         \n",
      "epoch 6  | loss: 1.20158 | val_0_logloss: 1.266   |  0:04:52s                         \n",
      "epoch 7  | loss: 1.19849 | val_0_logloss: 1.2086  |  0:05:33s                         \n",
      "epoch 8  | loss: 1.19733 | val_0_logloss: 1.21263 |  0:06:16s                         \n",
      "epoch 9  | loss: 1.20471 | val_0_logloss: 1.19363 |  0:06:59s                         \n",
      "epoch 10 | loss: 1.1974  | val_0_logloss: 1.1862  |  0:07:42s                         \n",
      "epoch 11 | loss: 1.1943  | val_0_logloss: 1.18845 |  0:08:25s                         \n",
      "epoch 12 | loss: 1.19461 | val_0_logloss: 1.19801 |  0:09:08s                         \n",
      "epoch 13 | loss: 1.20916 | val_0_logloss: 1.19072 |  0:09:48s                         \n",
      "epoch 14 | loss: 1.1985  | val_0_logloss: 1.23541 |  0:10:32s                         \n",
      "epoch 15 | loss: 1.19614 | val_0_logloss: 1.19035 |  0:11:12s                         \n",
      "epoch 16 | loss: 1.20468 | val_0_logloss: 1.17856 |  0:11:54s                         \n",
      "epoch 17 | loss: 1.18023 | val_0_logloss: 1.17524 |  0:12:36s                         \n",
      "epoch 18 | loss: 1.16638 | val_0_logloss: 1.17472 |  0:13:17s                         \n",
      "epoch 19 | loss: 1.17412 | val_0_logloss: 1.25894 |  0:14:00s                         \n",
      "epoch 20 | loss: 1.28704 | val_0_logloss: 1.19836 |  0:14:43s                         \n",
      "epoch 21 | loss: 1.20463 | val_0_logloss: 1.19872 |  0:15:25s                         \n",
      "epoch 22 | loss: 1.20616 | val_0_logloss: 1.19856 |  0:16:07s                         \n",
      "epoch 23 | loss: 1.2184  | val_0_logloss: 1.19747 |  0:16:47s                         \n",
      "epoch 24 | loss: 1.1982  | val_0_logloss: 1.19873 |  0:17:30s                         \n",
      "epoch 25 | loss: 1.18867 | val_0_logloss: 1.19869 |  0:18:13s                         \n",
      "epoch 26 | loss: 1.1912  | val_0_logloss: 1.1915  |  0:18:54s                         \n",
      "epoch 27 | loss: 1.19072 | val_0_logloss: 1.19417 |  0:19:35s                         \n",
      "epoch 28 | loss: 1.18287 | val_0_logloss: 1.18391 |  0:20:15s                         \n",
      "                                                                                      \n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_logloss = 1.17472\n",
      "Best weights from best epoch are automatically used!                                  \n",
      "[4.67599780894767, 17.716346612036844, 21.945546626398375, 4.755824289030402, 1.2014413595556077, 1.2058480034706804, 1.2659958683061547, 1.20859841946706, 1.212634778018791, 1.193625449205219, 1.1862007409051425, 1.1884479785624127, 1.1980110812493932, 1.1907242628466443, 1.2354140401358438, 1.190348152661677, 1.1785638816432675, 1.175240978512357, 1.1747198172335356, 1.2589374783912062, 1.1983592988181957, 1.1987172029611923, 1.198561805308369, 1.1974656309906262, 1.1987261186688654, 1.1986909039604363, 1.1914990786996398, 1.194174180663711, 1.183905578703307]\n",
      "Device used : cuda                                                                    \n",
      "epoch 0  | loss: 0.92072 | val_0_logloss: 0.7602  |  0:00:55s                         \n",
      "epoch 1  | loss: 0.79541 | val_0_logloss: 1.738   |  0:01:50s                         \n",
      "epoch 2  | loss: 0.7835  | val_0_logloss: 0.77817 |  0:02:48s                         \n",
      "epoch 3  | loss: 0.76537 | val_0_logloss: 0.78314 |  0:03:44s                         \n",
      "epoch 4  | loss: 0.7662  | val_0_logloss: 0.77021 |  0:04:41s                         \n",
      "epoch 5  | loss: 0.78201 | val_0_logloss: 0.78191 |  0:05:37s                         \n",
      "epoch 6  | loss: 0.9052  | val_0_logloss: 0.76569 |  0:06:32s                         \n",
      "epoch 7  | loss: 0.76611 | val_0_logloss: 0.80528 |  0:07:24s                         \n",
      "epoch 8  | loss: 0.7663  | val_0_logloss: 0.77376 |  0:08:15s                         \n",
      "epoch 9  | loss: 0.76736 | val_0_logloss: 0.85258 |  0:09:12s                         \n",
      "epoch 10 | loss: 0.76484 | val_0_logloss: 0.84671 |  0:10:08s                         \n",
      "                                                                                      \n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_logloss = 0.7602\n",
      "Best weights from best epoch are automatically used!                                  \n",
      "[0.7601979517106464, 1.7380006195591746, 0.7781732770081773, 0.7831442507758052, 0.7702080126105553, 0.7819052618760327, 0.7656949027636699, 0.8052814336159521, 0.7737588255365506, 0.8525816560177091, 0.846712056510494]\n",
      "Device used : cuda                                                                    \n",
      "epoch 0  | loss: 1.40722 | val_0_logloss: 4.55729 |  0:00:28s                         \n",
      "epoch 1  | loss: 1.16222 | val_0_logloss: 0.8543  |  0:00:57s                         \n",
      "epoch 2  | loss: 1.29094 | val_0_logloss: 1.19622 |  0:01:26s                         \n",
      "epoch 3  | loss: 1.06527 | val_0_logloss: 0.98721 |  0:01:52s                         \n",
      "epoch 4  | loss: 0.98842 | val_0_logloss: 1.00019 |  0:02:20s                         \n",
      "epoch 5  | loss: 0.97905 | val_0_logloss: 0.96831 |  0:02:48s                         \n",
      "epoch 6  | loss: 0.97609 | val_0_logloss: 0.98123 |  0:03:15s                         \n",
      "epoch 7  | loss: 0.97743 | val_0_logloss: 1.02173 |  0:03:43s                         \n",
      "epoch 8  | loss: 0.90863 | val_0_logloss: 0.82728 |  0:04:11s                         \n",
      "epoch 9  | loss: 0.84984 | val_0_logloss: 4.0798  |  0:04:39s                         \n",
      "epoch 10 | loss: 0.82715 | val_0_logloss: 0.80452 |  0:05:07s                         \n",
      "epoch 11 | loss: 0.81797 | val_0_logloss: 0.84908 |  0:05:35s                         \n",
      "epoch 12 | loss: 1.03342 | val_0_logloss: 1.95599 |  0:06:02s                         \n",
      "epoch 13 | loss: 0.93453 | val_0_logloss: 0.80581 |  0:06:31s                         \n",
      "epoch 14 | loss: 0.79999 | val_0_logloss: 0.79168 |  0:06:59s                         \n",
      "epoch 15 | loss: 0.85081 | val_0_logloss: 2.86334 |  0:07:26s                         \n",
      "epoch 16 | loss: 0.79172 | val_0_logloss: 0.78216 |  0:07:55s                         \n",
      "epoch 17 | loss: 0.85832 | val_0_logloss: 0.86292 |  0:08:22s                         \n",
      "epoch 18 | loss: 1.00983 | val_0_logloss: 1.0214  |  0:08:50s                         \n",
      "epoch 19 | loss: 0.92478 | val_0_logloss: 0.93622 |  0:09:18s                         \n",
      "epoch 20 | loss: 0.8717  | val_0_logloss: 0.81449 |  0:09:45s                         \n",
      "epoch 21 | loss: 0.93165 | val_0_logloss: 0.84925 |  0:10:12s                         \n",
      "epoch 22 | loss: 0.82974 | val_0_logloss: 0.83752 |  0:10:41s                         \n",
      "epoch 23 | loss: 0.84215 | val_0_logloss: 0.804   |  0:11:10s                         \n",
      "epoch 24 | loss: 0.83926 | val_0_logloss: 0.8634  |  0:11:38s                         \n",
      "epoch 25 | loss: 33.64932| val_0_logloss: 21.94555|  0:12:06s                         \n",
      "epoch 26 | loss: 28.63834| val_0_logloss: 17.71635|  0:12:35s                         \n",
      "                                                                                      \n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_logloss = 0.78216\n",
      "Best weights from best epoch are automatically used!                                  \n",
      "[4.5572881258908575, 0.8542957321681038, 1.1962154812219439, 0.9872114000083508, 1.0001893062219456, 0.9683077765302058, 0.9812267216475126, 1.0217278054864576, 0.8272806402419334, 4.079797492559539, 0.8045165978955724, 0.8490770390378942, 1.9559866889739987, 0.8058126822526905, 0.7916800206965234, 2.8633352474302005, 0.7821585550047988, 0.8629172156460481, 1.0213962975048787, 0.9362186971321003, 0.8144850173763889, 0.8492456039895531, 0.8375164519879479, 0.8039961060017506, 0.8634015564254931, 21.945546626398375, 17.716346612036844]\n",
      "Device used : cuda                                                                    \n",
      "epoch 0  | loss: 0.62833 | val_0_logloss: 0.49839 |  0:00:23s                         \n",
      "epoch 1  | loss: 0.47996 | val_0_logloss: 0.41634 |  0:00:46s                         \n",
      "epoch 2  | loss: 0.41781 | val_0_logloss: 0.37245 |  0:01:09s                         \n",
      "epoch 3  | loss: 0.382   | val_0_logloss: 0.34165 |  0:01:32s                         \n",
      "epoch 4  | loss: 0.35935 | val_0_logloss: 0.31774 |  0:01:56s                         \n",
      "epoch 5  | loss: 0.3393  | val_0_logloss: 0.30895 |  0:02:19s                         \n",
      "epoch 6  | loss: 0.32514 | val_0_logloss: 0.29297 |  0:02:42s                         \n",
      "epoch 7  | loss: 0.31485 | val_0_logloss: 0.28858 |  0:03:06s                         \n",
      "epoch 8  | loss: 0.30526 | val_0_logloss: 0.26956 |  0:03:29s                         \n",
      "epoch 9  | loss: 0.29808 | val_0_logloss: 0.25839 |  0:03:52s                         \n",
      "epoch 10 | loss: 0.29172 | val_0_logloss: 0.26653 |  0:04:15s                         \n",
      "epoch 11 | loss: 0.28782 | val_0_logloss: 0.25274 |  0:04:38s                         \n",
      "epoch 12 | loss: 0.28095 | val_0_logloss: 0.24115 |  0:05:01s                         \n",
      "epoch 13 | loss: 0.27702 | val_0_logloss: 0.23894 |  0:05:25s                         \n",
      "epoch 14 | loss: 0.27215 | val_0_logloss: 0.23719 |  0:05:48s                         \n",
      "epoch 15 | loss: 0.2701  | val_0_logloss: 0.24507 |  0:06:10s                         \n",
      "epoch 16 | loss: 0.26658 | val_0_logloss: 0.2391  |  0:06:33s                         \n",
      "epoch 17 | loss: 0.2636  | val_0_logloss: 0.23145 |  0:06:56s                         \n",
      "epoch 18 | loss: 0.25935 | val_0_logloss: 0.22445 |  0:07:20s                         \n",
      "epoch 19 | loss: 0.25934 | val_0_logloss: 0.22344 |  0:07:43s                         \n",
      "epoch 20 | loss: 0.25558 | val_0_logloss: 0.22344 |  0:08:06s                         \n",
      "epoch 21 | loss: 0.25202 | val_0_logloss: 0.21311 |  0:08:29s                         \n",
      "epoch 22 | loss: 0.25093 | val_0_logloss: 0.22643 |  0:08:52s                         \n",
      "epoch 23 | loss: 0.24815 | val_0_logloss: 0.21492 |  0:09:15s                         \n",
      "epoch 24 | loss: 0.24633 | val_0_logloss: 0.21276 |  0:09:39s                         \n",
      "epoch 25 | loss: 0.24511 | val_0_logloss: 0.21573 |  0:10:02s                         \n",
      "epoch 26 | loss: 0.24315 | val_0_logloss: 0.21426 |  0:10:26s                         \n",
      "epoch 27 | loss: 0.2416  | val_0_logloss: 0.21214 |  0:10:50s                         \n",
      "epoch 28 | loss: 0.24054 | val_0_logloss: 0.21145 |  0:11:13s                         \n",
      "epoch 29 | loss: 0.23991 | val_0_logloss: 0.20701 |  0:11:37s                         \n",
      "epoch 30 | loss: 0.23579 | val_0_logloss: 0.21131 |  0:12:00s                         \n",
      "epoch 31 | loss: 0.23466 | val_0_logloss: 0.19959 |  0:12:23s                         \n",
      "epoch 32 | loss: 0.23424 | val_0_logloss: 0.20015 |  0:12:47s                         \n",
      "epoch 33 | loss: 0.23402 | val_0_logloss: 0.20198 |  0:13:11s                         \n",
      "epoch 34 | loss: 0.23204 | val_0_logloss: 0.20762 |  0:13:34s                         \n",
      "epoch 35 | loss: 0.23248 | val_0_logloss: 0.21227 |  0:13:58s                         \n",
      "epoch 36 | loss: 0.22884 | val_0_logloss: 0.19494 |  0:14:21s                         \n",
      "epoch 37 | loss: 0.23003 | val_0_logloss: 0.20067 |  0:14:45s                         \n",
      "epoch 38 | loss: 0.22798 | val_0_logloss: 0.19741 |  0:15:08s                         \n",
      "epoch 39 | loss: 0.22817 | val_0_logloss: 0.19808 |  0:15:32s                         \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 36 and best_val_0_logloss = 0.19494\n",
      "Best weights from best epoch are automatically used!                                  \n",
      "[0.4983856665104854, 0.4163365280438191, 0.3724451446573846, 0.3416494300668587, 0.31774456847167865, 0.30894593168019596, 0.29296612695943675, 0.288581252077312, 0.26955765236250373, 0.25838614796488263, 0.2665262944977911, 0.25274053165052124, 0.24114748935082153, 0.2389383819505921, 0.23718926773022114, 0.2450713616434524, 0.2391017229988345, 0.23144906677477028, 0.22445309927359325, 0.2234402998974198, 0.22344312158789612, 0.2131128425236613, 0.22642925314261697, 0.21491821162937103, 0.21275917002253325, 0.21572533630134014, 0.21425870159922536, 0.2121403443796057, 0.21145363012982227, 0.20701213124757276, 0.21130753933503166, 0.19959332897107446, 0.20015331389080554, 0.20197808466370124, 0.20762446130980886, 0.21227211573174962, 0.19493960060580745, 0.20066837615072788, 0.19740825696087705, 0.1980781257666047]\n",
      "Device used : cuda                                                                     \n",
      "epoch 0  | loss: 0.77013 | val_0_logloss: 0.66306 |  0:00:54s                          \n",
      "epoch 1  | loss: 0.64375 | val_0_logloss: 0.60278 |  0:01:49s                          \n",
      "epoch 2  | loss: 0.60228 | val_0_logloss: 0.57564 |  0:02:43s                          \n",
      "epoch 3  | loss: 0.5506  | val_0_logloss: 0.50022 |  0:03:36s                          \n",
      "epoch 4  | loss: 0.50951 | val_0_logloss: 0.45339 |  0:04:30s                          \n",
      "epoch 5  | loss: 0.45913 | val_0_logloss: 0.40679 |  0:05:24s                          \n",
      "epoch 6  | loss: 0.43406 | val_0_logloss: 0.39767 |  0:06:18s                          \n",
      "epoch 7  | loss: 0.40108 | val_0_logloss: 0.34656 |  0:07:15s                          \n",
      "epoch 8  | loss: 0.37744 | val_0_logloss: 0.33261 |  0:08:08s                          \n",
      "epoch 9  | loss: 0.3533  | val_0_logloss: 0.30025 |  0:09:03s                          \n",
      "epoch 10 | loss: 0.35219 | val_0_logloss: 0.35684 |  0:09:57s                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | loss: 0.34324 | val_0_logloss: 0.3783  |  0:10:54s                          \n",
      "epoch 12 | loss: 0.32716 | val_0_logloss: 0.29531 |  0:11:50s                          \n",
      "epoch 13 | loss: 0.3047  | val_0_logloss: 0.28173 |  0:12:47s                          \n",
      "epoch 14 | loss: 0.30499 | val_0_logloss: 0.27735 |  0:13:42s                          \n",
      "epoch 15 | loss: 0.29236 | val_0_logloss: 0.25738 |  0:14:38s                          \n",
      "epoch 16 | loss: 0.28658 | val_0_logloss: 0.24243 |  0:15:30s                          \n",
      "epoch 17 | loss: 0.28697 | val_0_logloss: 0.23468 |  0:16:20s                          \n",
      "epoch 18 | loss: 0.27788 | val_0_logloss: 0.2531  |  0:17:15s                          \n",
      "epoch 19 | loss: 0.27277 | val_0_logloss: 0.2247  |  0:18:16s                          \n",
      "epoch 20 | loss: 0.27181 | val_0_logloss: 0.22053 |  0:19:12s                          \n",
      "epoch 21 | loss: 0.26885 | val_0_logloss: 0.22167 |  0:20:08s                          \n",
      "epoch 22 | loss: 0.26305 | val_0_logloss: 0.22179 |  0:21:02s                          \n",
      "epoch 23 | loss: 0.2688  | val_0_logloss: 0.24245 |  0:22:09s                          \n",
      "epoch 24 | loss: 0.26072 | val_0_logloss: 0.21346 |  0:23:30s                          \n",
      "epoch 25 | loss: 0.2511  | val_0_logloss: 0.22916 |  0:24:33s                          \n",
      "epoch 26 | loss: 0.24923 | val_0_logloss: 0.23862 |  0:25:27s                          \n",
      "epoch 27 | loss: 0.2514  | val_0_logloss: 0.20936 |  0:26:19s                          \n",
      "epoch 28 | loss: 0.25317 | val_0_logloss: 0.22173 |  0:27:14s                          \n",
      " 67%|██████▋   | 10/15 [2:30:57<1:09:16, 831.21s/trial, best loss: 0.16889440966047728]"
     ]
    }
   ],
   "source": [
    "trials=Trials()\n",
    "best=fmin(fn=tb_ll_cv, space=reg_params, algo=tpe.suggest, max_evals=15, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Io68SETkvGYX",
    "outputId": "6bc0c5da-2dab-4b73-b3c2-f3794ea501ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 2,\n",
       " 'feature_dim': 45.0,\n",
       " 'learning_rate': 0.015379819793208791,\n",
       " 'momentum': 0.3495512306646472,\n",
       " 'n_steps': 2.0,\n",
       " 'relaxation_factor': 1.023799674691017}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j_A67Km2ZVsh"
   },
   "outputs": [],
   "source": [
    "l_batch=[512, 1024, 2048, 4096, 8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXNvR6UYvHqm",
    "outputId": "1b8ea49d-a262-4509-a4ca-284ccc968fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 0.7206  | val_0_logloss: 1.44755 |  0:00:16s\n",
      "epoch 1  | loss: 0.54976 | val_0_logloss: 0.62954 |  0:00:33s\n",
      "epoch 2  | loss: 0.47888 | val_0_logloss: 0.43461 |  0:00:50s\n",
      "epoch 3  | loss: 0.42923 | val_0_logloss: 0.37827 |  0:01:08s\n",
      "epoch 4  | loss: 0.3881  | val_0_logloss: 0.34646 |  0:01:24s\n",
      "epoch 5  | loss: 0.3599  | val_0_logloss: 0.32503 |  0:01:41s\n",
      "epoch 6  | loss: 0.33709 | val_0_logloss: 0.31057 |  0:01:57s\n",
      "epoch 7  | loss: 0.32054 | val_0_logloss: 0.28365 |  0:02:14s\n",
      "epoch 8  | loss: 0.3058  | val_0_logloss: 0.27032 |  0:02:31s\n",
      "epoch 9  | loss: 0.28924 | val_0_logloss: 0.26184 |  0:02:49s\n",
      "epoch 10 | loss: 0.28428 | val_0_logloss: 0.24553 |  0:03:06s\n",
      "epoch 11 | loss: 0.27418 | val_0_logloss: 0.25463 |  0:03:23s\n",
      "epoch 12 | loss: 0.26724 | val_0_logloss: 0.23546 |  0:03:40s\n",
      "epoch 13 | loss: 0.25772 | val_0_logloss: 0.23191 |  0:03:56s\n",
      "epoch 14 | loss: 0.25169 | val_0_logloss: 0.22678 |  0:04:13s\n",
      "epoch 15 | loss: 0.24873 | val_0_logloss: 0.22497 |  0:04:31s\n",
      "epoch 16 | loss: 0.24224 | val_0_logloss: 0.21799 |  0:04:48s\n",
      "epoch 17 | loss: 0.23777 | val_0_logloss: 0.21083 |  0:05:05s\n",
      "epoch 18 | loss: 0.23364 | val_0_logloss: 0.2055  |  0:05:23s\n",
      "epoch 19 | loss: 0.23031 | val_0_logloss: 0.21229 |  0:05:40s\n",
      "epoch 20 | loss: 0.22749 | val_0_logloss: 0.19984 |  0:05:56s\n",
      "epoch 21 | loss: 0.22529 | val_0_logloss: 0.19451 |  0:06:13s\n",
      "epoch 22 | loss: 0.22112 | val_0_logloss: 0.20933 |  0:06:30s\n",
      "epoch 23 | loss: 0.2218  | val_0_logloss: 0.19946 |  0:06:47s\n",
      "epoch 24 | loss: 0.21848 | val_0_logloss: 0.19382 |  0:07:03s\n",
      "epoch 25 | loss: 0.21543 | val_0_logloss: 0.18569 |  0:07:21s\n",
      "epoch 26 | loss: 0.21353 | val_0_logloss: 0.19234 |  0:07:38s\n",
      "epoch 27 | loss: 0.21155 | val_0_logloss: 0.18455 |  0:07:56s\n",
      "epoch 28 | loss: 0.21024 | val_0_logloss: 0.18175 |  0:08:14s\n",
      "epoch 29 | loss: 0.20726 | val_0_logloss: 0.18271 |  0:08:31s\n",
      "epoch 30 | loss: 0.20557 | val_0_logloss: 0.18454 |  0:08:48s\n",
      "epoch 31 | loss: 0.2026  | val_0_logloss: 0.17887 |  0:09:06s\n",
      "epoch 32 | loss: 0.20332 | val_0_logloss: 0.17783 |  0:09:23s\n",
      "epoch 33 | loss: 0.20102 | val_0_logloss: 0.17505 |  0:09:40s\n",
      "epoch 34 | loss: 0.19878 | val_0_logloss: 0.1737  |  0:09:58s\n",
      "epoch 35 | loss: 0.19894 | val_0_logloss: 0.17769 |  0:10:16s\n",
      "epoch 36 | loss: 0.19724 | val_0_logloss: 0.18245 |  0:10:33s\n",
      "epoch 37 | loss: 0.19643 | val_0_logloss: 0.17059 |  0:10:49s\n",
      "epoch 38 | loss: 0.19116 | val_0_logloss: 0.17972 |  0:11:06s\n",
      "epoch 39 | loss: 0.193   | val_0_logloss: 0.16889 |  0:11:23s\n",
      "epoch 40 | loss: 0.19156 | val_0_logloss: 0.16719 |  0:11:40s\n",
      "epoch 41 | loss: 0.1899  | val_0_logloss: 0.1697  |  0:11:57s\n",
      "epoch 42 | loss: 0.19021 | val_0_logloss: 0.16868 |  0:12:14s\n",
      "epoch 43 | loss: 0.1913  | val_0_logloss: 0.1709  |  0:12:31s\n",
      "epoch 44 | loss: 0.1894  | val_0_logloss: 0.1687  |  0:12:47s\n",
      "epoch 45 | loss: 0.18592 | val_0_logloss: 0.16849 |  0:13:04s\n",
      "epoch 46 | loss: 0.18746 | val_0_logloss: 0.16869 |  0:13:20s\n",
      "epoch 47 | loss: 0.18397 | val_0_logloss: 0.16126 |  0:13:37s\n",
      "epoch 48 | loss: 0.18459 | val_0_logloss: 0.16368 |  0:13:54s\n",
      "epoch 49 | loss: 0.18217 | val_0_logloss: 0.16689 |  0:14:11s\n",
      "epoch 50 | loss: 0.18284 | val_0_logloss: 0.16711 |  0:14:28s\n",
      "epoch 51 | loss: 0.18227 | val_0_logloss: 0.16083 |  0:14:45s\n",
      "epoch 52 | loss: 0.18159 | val_0_logloss: 0.1607  |  0:15:02s\n",
      "epoch 53 | loss: 0.18072 | val_0_logloss: 0.1599  |  0:15:19s\n",
      "epoch 54 | loss: 0.18021 | val_0_logloss: 0.156   |  0:15:36s\n",
      "epoch 55 | loss: 0.17958 | val_0_logloss: 0.16367 |  0:15:53s\n",
      "epoch 56 | loss: 0.17978 | val_0_logloss: 0.15829 |  0:16:11s\n",
      "epoch 57 | loss: 0.17707 | val_0_logloss: 0.15828 |  0:16:28s\n",
      "epoch 58 | loss: 0.17782 | val_0_logloss: 0.16194 |  0:16:45s\n",
      "epoch 59 | loss: 0.17739 | val_0_logloss: 0.15569 |  0:17:01s\n",
      "epoch 60 | loss: 0.17584 | val_0_logloss: 0.15687 |  0:17:19s\n",
      "epoch 61 | loss: 0.17509 | val_0_logloss: 0.15751 |  0:17:36s\n",
      "epoch 62 | loss: 0.17881 | val_0_logloss: 0.15916 |  0:17:53s\n",
      "epoch 63 | loss: 0.1757  | val_0_logloss: 0.15907 |  0:18:10s\n",
      "epoch 64 | loss: 0.17255 | val_0_logloss: 0.15152 |  0:18:27s\n",
      "epoch 65 | loss: 0.17289 | val_0_logloss: 0.15727 |  0:18:44s\n",
      "epoch 66 | loss: 0.17157 | val_0_logloss: 0.15262 |  0:19:00s\n",
      "epoch 67 | loss: 0.17114 | val_0_logloss: 0.15159 |  0:19:17s\n",
      "epoch 68 | loss: 0.17132 | val_0_logloss: 0.15233 |  0:19:35s\n",
      "epoch 69 | loss: 0.17081 | val_0_logloss: 0.15457 |  0:19:52s\n",
      "epoch 70 | loss: 0.17096 | val_0_logloss: 0.14986 |  0:20:09s\n",
      "epoch 71 | loss: 0.17218 | val_0_logloss: 0.15293 |  0:20:26s\n",
      "epoch 72 | loss: 0.17044 | val_0_logloss: 0.15166 |  0:20:43s\n",
      "epoch 73 | loss: 0.1677  | val_0_logloss: 0.14925 |  0:21:01s\n",
      "epoch 74 | loss: 0.16961 | val_0_logloss: 0.15667 |  0:21:17s\n",
      "epoch 75 | loss: 0.16869 | val_0_logloss: 0.15575 |  0:21:34s\n",
      "epoch 76 | loss: 0.168   | val_0_logloss: 0.15089 |  0:21:51s\n",
      "epoch 77 | loss: 0.16679 | val_0_logloss: 0.15106 |  0:22:07s\n",
      "epoch 78 | loss: 0.16703 | val_0_logloss: 0.15125 |  0:22:24s\n",
      "epoch 79 | loss: 0.16592 | val_0_logloss: 0.15558 |  0:22:40s\n",
      "epoch 80 | loss: 0.16797 | val_0_logloss: 0.15154 |  0:22:58s\n",
      "epoch 81 | loss: 0.16575 | val_0_logloss: 0.14681 |  0:23:14s\n",
      "epoch 82 | loss: 0.16563 | val_0_logloss: 0.1645  |  0:23:30s\n",
      "epoch 83 | loss: 0.17011 | val_0_logloss: 0.14336 |  0:23:48s\n",
      "epoch 84 | loss: 0.16425 | val_0_logloss: 0.151   |  0:24:04s\n",
      "epoch 85 | loss: 0.16378 | val_0_logloss: 0.14716 |  0:24:21s\n",
      "epoch 86 | loss: 0.16302 | val_0_logloss: 0.14892 |  0:24:38s\n",
      "epoch 87 | loss: 0.16579 | val_0_logloss: 0.15087 |  0:24:54s\n",
      "epoch 88 | loss: 0.16528 | val_0_logloss: 0.15266 |  0:25:11s\n",
      "epoch 89 | loss: 0.16311 | val_0_logloss: 0.1456  |  0:25:27s\n",
      "epoch 90 | loss: 0.16138 | val_0_logloss: 0.14479 |  0:25:44s\n",
      "epoch 91 | loss: 0.16213 | val_0_logloss: 0.14513 |  0:26:01s\n",
      "epoch 92 | loss: 0.16194 | val_0_logloss: 0.14713 |  0:26:18s\n",
      "epoch 93 | loss: 0.16203 | val_0_logloss: 0.15352 |  0:26:35s\n",
      "\n",
      "Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_logloss = 0.14336\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "model=TabNetClassifier(n_a=int(best['feature_dim']), n_d=int(best['feature_dim']), n_steps=int(best['n_steps']), momentum=best['momentum'], gamma=best['relaxation_factor'], optimizer_params=dict(lr=best['learning_rate']), device_name='cuda')\n",
    "model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], batch_size=l_batch[best['batch_size']],max_epochs=100,eval_metric=['logloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iJvtp-6vKbW",
    "outputId": "000595e7-aebc-45f1-b1e0-52b8878e4dcc"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 7 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d9d8651aebf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/seathru/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 7 is out of bounds."
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss1 = criterion(torch.from_numpy(model.predict_proba(x_test)),torch.from_numpy(y_test))\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcOy13oJgBz5",
    "outputId": "00f1f04b-7417-4e7a-d372-39b0ad7e46b8"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEClaFjrgDUr",
    "outputId": "ba14b950-6004-4103-f4d2-b7d1aad51add"
   },
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sr7RnOsLgGl-",
    "outputId": "7bf81c5b-90f4-422f-8448-101cf59bd074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1991425e-02, 9.4800615e-01, 1.2978884e-07, ..., 1.4461514e-06,\n",
       "        1.5490480e-07, 6.8128156e-07],\n",
       "       [5.3208017e-01, 1.1642542e-03, 2.5867664e-07, ..., 1.6498728e-06,\n",
       "        2.8742832e-06, 4.6675071e-01],\n",
       "       [9.9990118e-01, 9.2089635e-05, 2.1134962e-10, ..., 4.2900131e-11,\n",
       "        1.2059405e-08, 6.6378052e-06],\n",
       "       ...,\n",
       "       [9.9987447e-01, 1.2544439e-04, 1.1839769e-11, ..., 2.5782018e-08,\n",
       "        1.8053200e-09, 1.5870403e-07],\n",
       "       [2.7516036e-04, 9.9960035e-01, 5.3013913e-08, ..., 1.2355097e-04,\n",
       "        6.4728880e-09, 9.1813092e-07],\n",
       "       [6.9696020e-04, 9.9929917e-01, 1.4977154e-06, ..., 9.8182662e-09,\n",
       "        7.5911366e-09, 2.3500834e-06]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "sWtl4k0qgnX9"
   },
   "outputs": [],
   "source": [
    "a=model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "xL0Ieb2sgYj5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(a).to_csv(\"data_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a).to_csv(\"tabnet_forestcover.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data_forest_hyper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
