{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0y-jubQY3Ge",
        "outputId": "7d5422e6-66d2-41d3-fc43-1f595cfc8866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'node'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ganeshtmvs/node.git\n",
        "#chande the directory to node \n",
        "#%cd /content/drive/MyDrive/6th_Sem/node"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu_GhcSuhoPU",
        "outputId": "fead6096-cc6d-49c7-acea-626690c30375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ee5180/node"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5FU34Tg2QU",
        "outputId": "1e1c9f5c-da02-4721-849f-39a443c51721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ee5180/node\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "-jlSzT2NODbu",
        "outputId": "f3029ad1-5cf1-4cc6-f223-126f37678dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/facebookresearch/qhoptim/archive/master.zip (from -r requirements.txt (line 12))\n",
            "  Downloading https://github.com/facebookresearch/qhoptim/archive/master.zip\n",
            "\u001b[K     / 6.5 MB 6.8 MB/s\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=0.13 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.0.2)\n",
            "Collecting catboost==0.12.2\n",
            "  Downloading catboost-0.12.2-cp37-none-manylinux1_x86_64.whl (55.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 55.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting xgboost==0.81\n",
            "  Downloading xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 201 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.64.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.3.5)\n",
            "Requirement already satisfied: prefetch_generator in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
            "Collecting enum34\n",
            "  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost==0.12.2->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.17.3)\n",
            "Building wheels for collected packages: qhoptim\n",
            "  Building wheel for qhoptim (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qhoptim: filename=qhoptim-1.1.0-py3-none-any.whl size=20333 sha256=b5bb3de68c78561028462fab2708021140ceb247f9ef1eedd8e4dd0e0f662ac5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ejqhmry3/wheels/4e/8d/ab/172397a202926a7ebf44245fdb7e8c91fb85d3108fb0b556f9\n",
            "Successfully built qhoptim\n",
            "Installing collected packages: enum34, xgboost, tensorboardX, qhoptim, catboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed catboost-0.12.2 enum34-1.1.10 qhoptim-1.1.0 tensorboardX-2.5 xgboost-0.81\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5FHvzMNyLyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200e0749-15c8-4c4d-d4a5-52acb41f01c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "  if not os.path.exists('./data'):\n",
        "    os.makedirs('./data')\n",
        "\n",
        "  filename = wget.download(URL)\n",
        "  with gzip.open(filename, 'rb') as f_in:\n",
        "    with open('data/covtype.csv', 'wb') as f_out:\n",
        "      shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "  df = pd.read_csv('data/covtype.csv')\n",
        "  n_total = len(df)\n",
        "\n",
        "  # Train, val and test split follows\n",
        "  # Rory Mitchell, Andrey Adinets, Thejaswi Rao, and Eibe Frank.\n",
        "  # Xgboost: Scalable GPU accelerated learning. arXiv:1806.11248, 2018.\n",
        "\n",
        "  train_val_indices, test_indices = train_test_split(\n",
        "      range(n_total), test_size=0.2, random_state=0)\n",
        "  train_indices, val_indices = train_test_split(\n",
        "      train_val_indices, test_size=0.2 / 0.6, random_state=0)\n",
        "\n",
        "  traindf = df.iloc[train_indices]\n",
        "  valdf = df.iloc[val_indices]\n",
        "  testdf = df.iloc[test_indices]\n",
        "  traindf = traindf.sample(frac=1)\n",
        "\n",
        "  traindf.to_csv('data/train_covertype.csv', index=False, header=False)\n",
        "  valdf.to_csv('data/val_covertype.csv', index=False, header=False)\n",
        "  testdf.to_csv('data/test_covertype.csv', index=False, header=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import gzip\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n3OEbRqGRd1",
        "outputId": "87d8fe50-107a-40c2-d0ca-69925175cbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=5f13da1341237077f3a635802c345472af3e53d8718b71021c1f23562185a569\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fast_ml\n",
        "def convert_to_one_hot(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        l = [0 for i in range(7)]\n",
        "        l[y[i] - 1] = 1\n",
        "        if not seen:\n",
        "            y_o = np.array(l.copy())\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, l.copy()])\n",
        "    return y_o\n",
        "data = pd.read_csv('/content/drive/MyDrive/ee5180/node/shrutime/Churn_Modelling.csv')\n",
        "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n",
        "\n",
        "\n",
        "def convert_country(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        if not seen:\n",
        "            y_o = np.array([m1[y[i]]])\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, [m1[y[i]]]])\n",
        "    return y_o\n",
        "\n",
        "def convert_gender(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        if not seen:\n",
        "            y_o = np.array([m2[y[i]]])\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, [m2[y[i]]]])\n",
        "    return y_o\n",
        "    \n",
        "m1 = {\"France\" : 0, \"Spain\" : 1, \"Germany\" : 2}\n",
        "m2 = {\"Male\" : 0, \"Female\" : 1}\n",
        "\n",
        "y = data[\"Geography\"]\n",
        "y = y.to_numpy()\n",
        "y = convert_country(y)\n",
        "data = data.drop(\"Geography\", axis = 1)\n",
        "data[\"Geography\"] = y\n",
        "\n",
        "y = data[\"Gender\"]\n",
        "y = y.to_numpy()\n",
        "y = convert_gender(y)\n",
        "data = data.drop(\"Gender\", axis = 1)\n",
        "data[\"Gender\"] = y\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "# x_train = train.drop(\"Cover_Type\", axis = 1)\n",
        "# y_train = train[train.columns[-1]]\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = train_valid_test_split(data, target = 'Exited', \n",
        "                                                                            train_size=0.8, valid_size=0.1, test_size = 0.1)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "#y_train = np.expand_dims(y_train, axis=1)\n",
        "#y_train = convert_to_one_hot(y_train)\n",
        "\n",
        "\n",
        "x_valid = x_valid.to_numpy()\n",
        "y_valid = y_valid.to_numpy()\n",
        "#y_valid = np.expand_dims(y_valid, axis=1)\n",
        "#y_valid = convert_to_one_hot(y_valid)\n",
        "\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "#y_test = np.expand_dims(y_test, axis=1)\n",
        "#y_test = convert_to_one_hot(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_valid.shape)\n",
        "print(y_valid.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "print(data.shape)\n",
        "y = data[data.columns[-1]]\n",
        "y = y.to_numpy()\n",
        "target_cols = [\"Exited\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "kExz5EA_Nvl0",
        "outputId": "9f0692ef-b244-47a2-a9fb-c8d16af2b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 20 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 744 kB/s \n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ed3293d8ff67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0my_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ee5180/node/shrutime/Churn_Modelling.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RowNumber\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CustomerId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Surname\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/ee5180/node/shrutime/train_shrutime.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/ee5180/node/shrutime/test_shrutime.csv')\n",
        "#val=pd.read_csv('/content/drive/MyDrive/ee5180/node/data/val_covertype.csv')\n"
      ],
      "metadata": {
        "id": "XhTMYITxF4JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=train.drop(labels=['Exited'],axis=1)\n",
        "y=train['Exited']"
      ],
      "metadata": {
        "id": "rwRV2dY2FoP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test.drop(labels=['Exited'],axis=1)\n",
        "y_test=test['Exited'] "
      ],
      "metadata": {
        "id": "_600-GBhRP-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val=train_test_split(X,y,train_size=0.8)"
      ],
      "metadata": {
        "id": "Q2tA7K69GtmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg8JrnboGvTx",
        "outputId": "b606ac27-94a0-4797-863c-f0645edc8fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7971    0\n",
              "6992    0\n",
              "326     1\n",
              "2338    0\n",
              "4996    0\n",
              "       ..\n",
              "5608    0\n",
              "3755    0\n",
              "4743    0\n",
              "7907    1\n",
              "2665    0\n",
              "Name: Exited, Length: 6400, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=x_train.to_numpy()\n",
        "y_train=y_train.to_numpy()\n",
        "x_val=x_val.to_numpy()\n",
        "y_val=y_val.to_numpy()\n",
        "x_test=x_test.to_numpy()\n",
        "y_test=y_test.to_numpy()\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "set(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuWs6mPRG8LA",
        "outputId": "9b7f2914-707d-4415-adf6-89b6a969ef66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "print(train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c2WVWDrHBAp",
        "outputId": "3c6da590-d7d6-40d2-c418-7fdf3359d7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6400, 10)\n",
            "(6400,)\n",
            "(1600, 10)\n",
            "(1600,)\n",
            "(2000, 10)\n",
            "(2000,)\n",
            "(8000, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Os9Z9ItyyOi"
      },
      "outputs": [],
      "source": [
        "# Dataset size\n",
        "# N_TRAIN_SAMPLES = 309871\n",
        "N_VAL_SAMPLES = 154937\n",
        "N_TEST_SAMPLES = 116203\n",
        "NUM_FEATURES = 54\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "# All feature columns in the data\n",
        "LABEL_COLUMN = \"Covertype\"\n",
        "\n",
        "BOOL_COLUMNS = [\n",
        "    \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
        "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
        "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
        "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
        "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
        "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
        "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
        "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
        "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
        "    \"Soil_Type40\"\n",
        "]\n",
        "\n",
        "INT_COLUMNS = [\n",
        "    \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
        "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
        "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
        "    \"Horizontal_Distance_To_Fire_Points\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCdVg4CXzQIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80527ca-0b74-499a-8af2-a51184802d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.4.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 40 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 61 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 71 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 81 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 86 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.4.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import gzip\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import hyperopt\n",
        "from hyperopt import hp\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "from hyperopt import fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
        "from hyperopt.pyll.base import scope\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import math\n",
        "\n",
        "import time\n",
        "!pip install category_encoders\n",
        "from category_encoders import LeaveOneOutEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import gzip\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from qhoptim.pyt import QHAdam\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RB96YELzf9G"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/6th_Sem/node/data/train_covertype.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/6th_Sem/node/data/test_covertype.csv')\n",
        "val=pd.read_csv('/content/drive/MyDrive/6th_Sem/node/data/val_covertype.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG6rxL5Lz2d1"
      },
      "outputs": [],
      "source": [
        "train.columns=[\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
        "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
        "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
        "    \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
        "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
        "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
        "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
        "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
        "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
        "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
        "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
        "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
        "    \"Soil_Type40\", \"Covertype\"]\n",
        "test.columns=[\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
        "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
        "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
        "    \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
        "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
        "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
        "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
        "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
        "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
        "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
        "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
        "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
        "    \"Soil_Type40\", \"Covertype\"]\n",
        "val.columns=[\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
        "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
        "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
        "    \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
        "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
        "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
        "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
        "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
        "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
        "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
        "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
        "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
        "    \"Soil_Type40\", \"Covertype\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ftBGh_70f0f"
      },
      "outputs": [],
      "source": [
        "#train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmL-nCAz0lCT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_train = np.expand_dims(y_train, axis=1)\n",
        "#y_train = convert_to_one_hot(y_train)\n",
        "\n",
        "\n",
        "x_valid = x_valid.to_numpy()\n",
        "y_valid = y_valid.to_numpy()\n",
        "y_valid = np.expand_dims(y_valid, axis=1)\n",
        "#y_valid = convert_to_one_hot(y_valid)\n",
        "\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "y_test = np.expand_dims(y_test, axis=1)\n",
        "#y_test = convert_to_one_hot(y_"
      ],
      "metadata": {
        "id": "yA--_ktudebK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_valid = x_valid.astype('float32')\n",
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-PiW_TYQNpL",
        "outputId": "a8b4f0b1-c6b1-451e-a441-9ac8c78bf507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.2900000e+02, 4.6000000e+01, 5.0000000e+00, ..., 1.0401661e+05,\n",
              "        2.0000000e+00, 0.0000000e+00],\n",
              "       [4.9500000e+02, 3.8000000e+01, 2.0000000e+00, ..., 4.7089719e+04,\n",
              "        0.0000000e+00, 1.0000000e+00],\n",
              "       [7.7500000e+02, 2.8000000e+01, 9.0000000e+00, ..., 1.4933102e+05,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       ...,\n",
              "       [6.6700000e+02, 2.4000000e+01, 4.0000000e+00, ..., 1.8032983e+05,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [6.0200000e+02, 5.6000000e+01, 3.0000000e+00, ..., 4.1761699e+03,\n",
              "        0.0000000e+00, 1.0000000e+00],\n",
              "       [5.3700000e+02, 3.7000000e+01, 7.0000000e+00, ..., 1.1769058e+05,\n",
              "        2.0000000e+00, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "id": "N7o2sYKCZUKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcuR8D5j5EJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbef9ff-4533-43af-9071-8906414de6d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5, 6, 7}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_train=train.drop(labels=['Covertype'],axis=1)\n",
        "y_train=train['Covertype']\n",
        "x_val=val.drop(labels=['Covertype'],axis=1)\n",
        "y_val=val['Covertype']\n",
        "x_train=x_train.to_numpy()\n",
        "y_train=y_train.to_numpy()\n",
        "x_val=x_val.to_numpy()\n",
        "y_val=y_val.to_numpy()\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "set(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_train)):\n",
        "  temp = y_train[i] \n",
        "  y_train[i] = temp - 1\n",
        "set(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "von6pEq0jW3L",
        "outputId": "a01f3767-c525-418e-f401-1dc49d4ccf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_val)):\n",
        "  temp = y_val[i] \n",
        "  y_val[i] = temp - 1\n",
        "set(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_42tT2EHjvWF",
        "outputId": "3cc1ab63-f6dc-4cd0-e919-4fd8ba23eeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan = []\n",
        "for y in y_train:\n",
        "  gan.append(y[0])\n",
        "gan"
      ],
      "metadata": {
        "id": "F1OQoqixj5CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lib"
      ],
      "metadata": {
        "id": "8t3Vzta4TD4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'cpu'\n",
        "\n",
        "print(f'Using {device}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggom7D5zfVyW",
        "outputId": "83743c75-11e3-40dd-a4d5-65a4e8583073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "jPgcR7YrgDkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = math.floor(time.time())\n",
        "experiment_name = f'node_shrutime_{ts}'"
      ],
      "metadata": {
        "id": "rWyOt3Ioa0hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = x_train.shape[1]\n",
        "num_classes = len(set(y_train))\n",
        "NUM_FEATURES = num_features\n",
        "NUM_CLASSES = num_classes\n",
        "num_classes"
      ],
      "metadata": {
        "id": "SwiG8m9RPGsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38158ba2-c320-4eea-8488-40a141e984f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    lib.DenseBlock(NUM_FEATURES,\n",
        "                   layer_dim=128,\n",
        "                   num_layers=3,\n",
        "                   tree_dim=NUM_CLASSES,\n",
        "                    depth=6,\n",
        "                   flatten_output=False,\n",
        "                   choice_function=lib.entmax15,\n",
        "                   bin_function=lib.entmoid15),\n",
        "    lib.Lambda(lambda x: x[..., :NUM_CLASSES].mean(dim=-2)),\n",
        ").to(device)\n",
        "with torch.no_grad():\n",
        "    \n",
        "    res = model(torch.as_tensor( (x_train[:2000]), device=device))\n",
        "    # trigger data-aware init\n",
        "#From the original code \n",
        "#find it at one of the notebooks in  /content/drive/......./node/notebooks"
      ],
      "metadata": {
        "id": "bl-eGPIQYqO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = lib.Lambda(lambda x: x[..., :NUM_CLASSES].mean(dim=-2))"
      ],
      "metadata": {
        "id": "U2C50NvqYeMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lib.DenseBlock.num_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "DwAgB0i4YhNA",
        "outputId": "ec6576b1-0a2f-4a39-fe85-c7a6117be578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-f43311c00536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'DenseBlock' has no attribute 'num_layers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = lib.Trainer(\n",
        "    model=model, loss_function=F.cross_entropy,\n",
        "    experiment_name=experiment_name,\n",
        "    learning_rate=1,\n",
        "    warm_start=False,\n",
        "    total_tree_count = 1024,\n",
        "    Optimizer=QHAdam,\n",
        "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
        "    verbose=True,\n",
        "    n_last_checkpoints=5\n",
        ")"
      ],
      "metadata": {
        "id": "I5mAfKz2Zfh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, err_history = [], []\n",
        "best_val_err = 1.0\n",
        "best_step = 0\n",
        "early_stopping_rounds = 2500\n",
        "report_frequency = 1000"
      ],
      "metadata": {
        "id": "GyPo88d-ZiQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in lib.iterate_minibatches(x_train,\n",
        "                                     y_train,\n",
        "                                     batch_size=512, \n",
        "                                     shuffle=True,\n",
        "                                     epochs=float('inf')):\n",
        "    metrics = trainer.train_on_batch(*batch, device=device)\n",
        "    \n",
        "    loss_history.append(metrics['loss'])\n",
        "\n",
        "    if trainer.step % report_frequency == 0:\n",
        "        trainer.save_checkpoint()\n",
        "        trainer.average_checkpoints(out_tag='avg')\n",
        "        trainer.load_checkpoint(tag='avg')\n",
        "        err = trainer.evaluate_classification_error(\n",
        "            x_val,\n",
        "            y_val,\n",
        "            device=device,\n",
        "            batch_size=128)\n",
        "        \n",
        "        if err < best_val_err:\n",
        "            best_val_err = err\n",
        "            best_step = trainer.step\n",
        "            trainer.save_checkpoint(tag='best')\n",
        "        \n",
        "        err_history.append(err)\n",
        "        trainer.load_checkpoint()  # last\n",
        "        trainer.remove_old_temp_checkpoints()\n",
        "            \n",
        "        clear_output(True)\n",
        "        \n",
        "        print(\"Loss %.5f\" % (metrics['loss']))\n",
        "        print(\"Val Error Rate: %0.5f\" % (err))\n",
        "        \n",
        "    if trainer.step > best_step + early_stopping_rounds:\n",
        "        print('BREAK. There is no improvement for {} steps'.format(early_stopping_rounds))\n",
        "        print(\"Best step: \", best_step)\n",
        "        print(\"Best Val Error Rate: %0.5f\" % (best_val_err))\n",
        "        break"
      ],
      "metadata": {
        "id": "oxjjO1sCZkf_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "80f51442-bd0a-4271-ff53-41616012c7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 0.23236\n",
            "Val Error Rate: 0.15125\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c1476dea575f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                      epochs=float('inf')):\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, device, *batch)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uUPTTfWlEbZ",
        "outputId": "1388b708-b7ef-4c31-c9a5-9a1ea455e245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.0500000e+02, 6.4000000e+01, 3.0000000e+00, ..., 1.4657366e+05,\n",
              "        2.0000000e+00, 1.0000000e+00],\n",
              "       [7.0000000e+02, 4.4000000e+01, 9.0000000e+00, ..., 1.4228766e+05,\n",
              "        1.0000000e+00, 0.0000000e+00],\n",
              "       [7.0800000e+02, 5.1000000e+01, 8.0000000e+00, ..., 9.2920039e+04,\n",
              "        0.0000000e+00, 1.0000000e+00],\n",
              "       ...,\n",
              "       [6.3600000e+02, 3.1000000e+01, 9.0000000e+00, ..., 7.4641898e+04,\n",
              "        2.0000000e+00, 1.0000000e+00],\n",
              "       [6.5700000e+02, 4.1000000e+01, 8.0000000e+00, ..., 6.6463617e+04,\n",
              "        1.0000000e+00, 0.0000000e+00],\n",
              "       [6.9500000e+02, 3.6000000e+01, 2.0000000e+00, ..., 1.6774955e+05,\n",
              "        0.0000000e+00, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def opt_fn(search_space):\n",
        "  print(search_space)\n",
        "  best_val_err = 1.0\n",
        "  best_step = 0\n",
        "  early_stopping_rounds = 2500\n",
        "  report_frequency = 1000\n",
        "  experiment_name = 'debug' # this bypasses some code that will be executed each time otherwise\n",
        "  \n",
        "  model = nn.Sequential(\n",
        "      lib.DenseBlock(NUM_FEATURES,\n",
        "                     layer_dim=128,\n",
        "                     num_layers=int(search_space['num_layers']),\n",
        "                     tree_dim=NUM_CLASSES,\n",
        "                     flatten_output=False,\n",
        "                     depth=int(search_space['depth']),\n",
        "                     choice_function=lib.entmax15,\n",
        "                     bin_function=lib.entmoid15),\n",
        "      lib.Lambda(lambda x: x[..., :NUM_CLASSES].mean(dim=-2)),\n",
        "    ).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    res = model(torch.as_tensor(x_train[:2000], device=device))\n",
        "    # trigger data-aware init\n",
        "\n",
        "  trainer = lib.Trainer(\n",
        "    model=model, loss_function=F.cross_entropy,\n",
        "    experiment_name=experiment_name,\n",
        "    warm_start=False,\n",
        "    total_tree_count = search_space['total_tree_count'] ,\n",
        "    learning_rate=search_space['learning_rate'],\n",
        "    Optimizer=QHAdam,\n",
        "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
        "    verbose=True,\n",
        "    n_last_checkpoints=5\n",
        "  )\n",
        "\n",
        "  for batch in lib.iterate_minibatches(x_train,\n",
        "                                     y_train,\n",
        "                                     batch_size=512, \n",
        "                                     shuffle=True,\n",
        "                                     epochs=float('inf')):\n",
        "    \n",
        "    metrics = trainer.train_on_batch(*batch, device=device)\n",
        "    \n",
        "\n",
        "    if trainer.step % report_frequency == 0:\n",
        "          err = trainer.evaluate_classification_error(\n",
        "              x_val,\n",
        "              y_val,\n",
        "              device=device,\n",
        "              batch_size=128)\n",
        "        \n",
        "          if err < best_val_err:\n",
        "              best_val_err = err\n",
        "              best_step = trainer.step\n",
        "              opt_metric = best_val_err\n",
        "          print(\"Loss %.5f\" % (metrics['loss']))\n",
        "          print(\"Val Error Rate: %0.5f\" % (err))\n",
        "          \n",
        "    if trainer.step > best_step + early_stopping_rounds:\n",
        "          opt_metric = best_val_err\n",
        "          break\n",
        "          \n",
        "  return {'loss': opt_metric, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "_EiCMwKgtLN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
        "                'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
        "                'depth': hp.quniform('depth', 2, 7, 1)\n",
        "    }"
      ],
      "metadata": {
        "id": "3XjgP-WHUU_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "low = math.exp(-5)\n",
        "high = math.exp(-4)\n",
        "search_space = {\n",
        "                'num_layers': hp.choice('num_layers', [2,4,8]),\n",
        "                'depth': hp.choice('depth',[6,8] ),\n",
        "                'learning_rate' : hp.loguniform('learning_rate', -5, 0),\n",
        "                'total_tree_count' : hp.choice('total_tree_count', [1024,2048]),\n",
        "    }\n",
        "#'layer_dim': hp.choice('layer_dim', [512,1024])"
      ],
      "metadata": {
        "id": "_P-dkhCtXZfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27SFCdX0dfBI",
        "outputId": "3558fca7-4fb1-480c-a2ef-942e3d63cc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006737946999085467"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3kUlHtbBlpOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best = fmin(fn=opt_fn, \n",
        "  #          space=search_space, \n",
        "   #        algo=tpe.suggest, \n",
        "      #      max_evals=50) \n",
        "trials = Trials()\n",
        "best = fmin(fn=opt_fn, \n",
        "            space=search_space, \n",
        "            algo=tpe.suggest, \n",
        "            max_evals=10 \n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SNlB1apUhuH",
        "outputId": "70f02b8e-c89f-43bb-f15d-2f3fc5bb97af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'depth': 8, 'learning_rate': 0.3412678657979765, 'num_layers': 4, 'total_tree_count': 1024}\n",
            "Loss 0.35954\n",
            "Val Error Rate: 0.15000\n",
            "Loss 0.23244\n",
            "Val Error Rate: 0.15625\n",
            "Loss 0.23395\n",
            "Val Error Rate: 0.15875\n",
            "{'depth': 8, 'learning_rate': 0.6832683149711761, 'num_layers': 4, 'total_tree_count': 1024}\n",
            "Loss 0.34625\n",
            "Val Error Rate: 0.14438\n",
            "Loss 0.26454\n",
            "Val Error Rate: 0.14750\n",
            "Loss 0.22372\n",
            "Val Error Rate: 0.14750\n",
            "{'depth': 8, 'learning_rate': 0.4185450970118723, 'num_layers': 4, 'total_tree_count': 2048}\n",
            "Loss 0.35478\n",
            "Val Error Rate: 0.14500\n",
            "Loss 0.29188\n",
            "Val Error Rate: 0.14750\n",
            "Loss 0.21352\n",
            "Val Error Rate: 0.15313\n",
            "{'depth': 8, 'learning_rate': 0.008918580150939846, 'num_layers': 8, 'total_tree_count': 2048}\n",
            "Loss 0.28184\n",
            "Val Error Rate: 0.14813\n",
            "Loss 0.16723\n",
            "Val Error Rate: 0.16687\n",
            "Loss 0.15753\n",
            "Val Error Rate: 0.17250\n",
            "{'depth': 6, 'learning_rate': 0.09521980564158349, 'num_layers': 8, 'total_tree_count': 1024}\n",
            "Loss 0.33283\n",
            "Val Error Rate: 0.15063\n",
            "Loss 0.15556\n",
            "Val Error Rate: 0.15750\n",
            "Loss 0.12553\n",
            "Val Error Rate: 0.17188\n",
            "{'depth': 6, 'learning_rate': 0.16485238173057606, 'num_layers': 4, 'total_tree_count': 2048}\n",
            "Loss 0.33949\n",
            "Val Error Rate: 0.15500\n",
            "Loss 0.24501\n",
            "Val Error Rate: 0.14875\n",
            "Loss 0.20591\n",
            "Val Error Rate: 0.14688\n",
            "Loss 0.19506\n",
            "Val Error Rate: 0.15250\n",
            "Loss 0.18778\n",
            "Val Error Rate: 0.14875\n",
            "{'depth': 6, 'learning_rate': 0.08483869961465408, 'num_layers': 4, 'total_tree_count': 1024}\n",
            "Loss 0.34308\n",
            "Val Error Rate: 0.14875\n",
            "Loss 0.29934\n",
            "Val Error Rate: 0.14625\n",
            "Loss 0.24780\n",
            "Val Error Rate: 0.15125\n",
            "Loss 0.23926\n",
            "Val Error Rate: 0.15188\n",
            "{'depth': 8, 'learning_rate': 0.06258896246026169, 'num_layers': 4, 'total_tree_count': 1024}\n",
            "Loss 0.35655\n",
            "Val Error Rate: 0.14625\n",
            "Loss 0.27746\n",
            "Val Error Rate: 0.15125\n",
            "Loss 0.21301\n",
            "Val Error Rate: 0.15313\n",
            "{'depth': 8, 'learning_rate': 0.14182253779513448, 'num_layers': 2, 'total_tree_count': 2048}\n",
            "Loss 0.43322\n",
            "Val Error Rate: 0.21000\n",
            "Loss 0.38365\n",
            "Val Error Rate: 0.18000\n",
            "Loss 0.38107\n",
            "Val Error Rate: 0.17250\n",
            "Loss 0.39893\n",
            "Val Error Rate: 0.16562\n",
            "Loss 0.38116\n",
            "Val Error Rate: 0.16312\n",
            "Loss 0.34625\n",
            "Val Error Rate: 0.16250\n",
            "Loss 0.35579\n",
            "Val Error Rate: 0.16187\n",
            "Loss 0.34026\n",
            "Val Error Rate: 0.16312\n",
            "Loss 0.34079\n",
            "Val Error Rate: 0.16437\n",
            "{'depth': 8, 'learning_rate': 0.6277859289970577, 'num_layers': 2, 'total_tree_count': 2048}\n",
            "Loss 0.44016\n",
            "Val Error Rate: 0.21000\n",
            "Loss 0.41150\n",
            "Val Error Rate: 0.18750\n",
            "Loss 0.40019\n",
            "Val Error Rate: 0.17438\n",
            "Loss 0.34925\n",
            "Val Error Rate: 0.16750\n",
            "Loss 0.38023\n",
            "Val Error Rate: 0.16562\n",
            "Loss 0.33530\n",
            "Val Error Rate: 0.16812\n",
            "Loss 0.34384\n",
            "Val Error Rate: 0.16875\n",
            "100%|██████████| 10/10 [2:43:56<00:00, 983.61s/it, best loss: 0.144375] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model(torch.as_tensor(x_val, device=device))"
      ],
      "metadata": {
        "id": "KOBKjzTG3-ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss1 = trainer.loss_function(trainer.model(torch.as_tensor(x_val, device=device)), torch.as_tensor(y_val, device=device)).mean()"
      ],
      "metadata": {
        "id": "4NYSLxKwNePJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss2 = trainer.loss_function(res, torch.as_tensor(y_val, device=device)).mean()"
      ],
      "metadata": {
        "id": "tpK-rqCjOMkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEOASEqdN3xx",
        "outputId": "9f12d4e9-fb9c-4bdf-9490-ac741514fe15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best)\n",
        "# -> {'a': 1, 'c2': 0.01420615366247227}\n",
        "print(hyperopt.space_eval(search_space, best))\n",
        "# -> ('case 2', 0.01420615366247227}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIvi5ghcvLI",
        "outputId": "d51a062d-51c6-44a8-d201-037638c51b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'depth': 0, 'learning_rate': 1.0155719144534683, 'num_layers': 1, 'total_tree_count': 0}\n",
            "{'depth': 6, 'learning_rate': 1.0155719144534683, 'num_layers': 4, 'total_tree_count': 1024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best)\n",
        "# -> {'a': 1, 'c2': 0.01420615366247227}\n",
        "print(hyperopt.space_eval(search_space, best))\n",
        "# -> ('case 2', 0.01420615366247227}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZQExvwqOm-N",
        "outputId": "24c96f86-1bfd-468d-f024-2da75cdc5516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'depth': 1, 'learning_rate': 0.6832683149711761, 'num_layers': 1, 'total_tree_count': 0}\n",
            "{'depth': 8, 'learning_rate': 0.6832683149711761, 'num_layers': 4, 'total_tree_count': 1024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from copy import deepcopy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "from scipy import interp\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "V3q9HEjus0vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = math.floor(time.time())\n",
        "experiment_name = f'node_shrutime_{ts}'"
      ],
      "metadata": {
        "id": "wE5PoJACWFyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#params need to be replaced with with best params \n",
        "model = nn.Sequential(\n",
        "      lib.DenseBlock(NUM_FEATURES,\n",
        "                     layer_dim=128,\n",
        "                     num_layers=4,\n",
        "                     tree_dim=NUM_CLASSES,\n",
        "                     flatten_output=False,\n",
        "                     depth=8,\n",
        "                     choice_function=lib.entmax15,\n",
        "                     bin_function=lib.entmoid15),\n",
        "      lib.Lambda(lambda x: x[..., :NUM_CLASSES].mean(dim=-2)),\n",
        "    ).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    res = model(torch.as_tensor(x_train[:2000], device=device))\n",
        "    # trigger data-aware init\n",
        "trainer = lib.Trainer(\n",
        "    model=model, loss_function=F.cross_entropy,\n",
        "    experiment_name=experiment_name,\n",
        "    warm_start=False,\n",
        "    total_tree_count =1024 ,\n",
        "    learning_rate=0.006755694998907471,\n",
        "    Optimizer=QHAdam,\n",
        "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
        "    verbose=True,\n",
        "    n_last_checkpoints=5\n",
        "  )\n"
      ],
      "metadata": {
        "id": "YfW93sNJfoZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history, err_history = [], []\n",
        "best_val_err = 1.0\n",
        "best_step = 0\n",
        "early_stopping_rounds = 2500\n",
        "report_frequency = 1000"
      ],
      "metadata": {
        "id": "ZkMOcViDrc3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile1 = open(\"loss_hist2.txt\", \"a\")\n",
        "textfile1.write(\"ganesh\" + \"\\n\")\n",
        "textfile1.close()\n",
        "count = 1 "
      ],
      "metadata": {
        "id": "XWEeh0TpKYmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile2 = open(\"err_his2.txt\", \"a\")\n",
        "textfile2.write(\"gaensh\" + \"\\n\")\n",
        "textfile2.close()"
      ],
      "metadata": {
        "id": "5vH7LleXKcHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for batch in lib.iterate_minibatches(x_train,\n",
        "                                     y_train,\n",
        "                                     batch_size=512, \n",
        "                                     shuffle=True,\n",
        "                                     epochs=float('inf')):\n",
        "    metrics = trainer.train_on_batch(*batch, device=device)\n",
        "    \n",
        "    loss_history.append(metrics['loss'])\n",
        "    count = (count + 1)\n",
        "    count = count%200 \n",
        "    if(count==0):\n",
        "      textfile1 = open(\"loss_hist2.txt\", \"a\")\n",
        "      textfile1.write(str(metrics['loss']) + \"\\n\")\n",
        "      textfile1.close()\n",
        "    if trainer.step % report_frequency == 0:\n",
        "        trainer.save_checkpoint()\n",
        "        trainer.average_checkpoints(out_tag='avg')\n",
        "        trainer.load_checkpoint(tag='avg')\n",
        "        err = trainer.evaluate_classification_error(\n",
        "            x_val,\n",
        "            y_val,\n",
        "            device=device,\n",
        "            batch_size=128)\n",
        "        \n",
        "        if err < best_val_err:\n",
        "            best_val_err = err\n",
        "            best_step = trainer.step\n",
        "            trainer.save_checkpoint(tag='best')\n",
        "        \n",
        "        err_history.append(err)\n",
        "        textfile2 = open(\"err_his2.txt\", \"a\")\n",
        "        textfile2.write(str(err) + \"\\n\")\n",
        "        textfile2.close()\n",
        "        trainer.load_checkpoint()  # last\n",
        "        trainer.remove_old_temp_checkpoints()\n",
        "            \n",
        "        clear_output(True)\n",
        "        \n",
        "        print(\"Loss %.5f\" % (metrics['loss']))\n",
        "        print(\"Val Error Rate: %0.5f\" % (err))\n",
        "        \n",
        "    if trainer.step > best_step + early_stopping_rounds:\n",
        "        print('BREAK. There is no improvement for {} steps'.format(early_stopping_rounds))\n",
        "        print(\"Best step: \", best_step)\n",
        "        print(\"Best Val Error Rate: %0.5f\" % (best_val_err))\n",
        "        \n",
        "        \n",
        "        break"
      ],
      "metadata": {
        "id": "oa2b0KuFrI0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dd86f3-a64d-4dfd-ef13-ccd6e5f6c34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 0.18985\n",
            "Val Error Rate: 0.13000\n",
            "BREAK. There is no improvement for 2500 steps\n",
            "Best step:  3000\n",
            "Best Val Error Rate: 0.12312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_calc(y_true, y_pred, classes):\n",
        "\n",
        "    y_true_label = label_binarize(y_true, classes=classes)\n",
        "\n",
        "    y_pred_arg = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    cnf_matrix = confusion_matrix(y_true, y_pred_arg)\n",
        "\n",
        "    fp = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
        "    fn = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
        "    tp = np.diag(cnf_matrix)\n",
        "    tn = cnf_matrix.sum() - (fp + fn + tp)\n",
        "\n",
        "    fp = fp.astype(float)\n",
        "    fn = fn.astype(float)\n",
        "    tp = tp.astype(float)\n",
        "    tn = tn.astype(float)\n",
        "\n",
        "    tpr = tp/(tp+fn)\n",
        "    fpr = fp/(fp+tn)\n",
        "    precision = tp/(tp+fp)\n",
        "    acc = (tp+tn)/(tp+fp+fn+tn)\n",
        "\n",
        "    mean_acc = np.nanmean(acc)\n",
        "    mean_tpr = np.nanmean(tpr)\n",
        "    mean_fpr = np.nanmean(fpr)\n",
        "    mean_precision = np.nanmean(precision)\n",
        "\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc_list = []\n",
        "    pr_auc_list = []\n",
        "\n",
        "    if len(classes) == 2:\n",
        "        fpr, tpr, threshold_roc = roc_curve(y_true, y_pred[:, 1])\n",
        "\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_list.append(roc_auc)\n",
        "        \n",
        "        precision, recall, threshold_pr = precision_recall_curve(y_true,\n",
        "                                                            y_pred[:, 1])\n",
        "        \n",
        "        pr_auc = auc(recall, precision)\n",
        "        pr_auc_list.append(pr_auc)\n",
        "\n",
        "    else:\n",
        "        for i in range(y_pred.shape[1]):\n",
        "            fpr[i], tpr[i], threshold_roc = roc_curve(y_true_label[:, i], y_pred[:, i])\n",
        "            # roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "            roc_auc = auc(fpr[i], tpr[i])\n",
        "            roc_auc_list.append(roc_auc)\n",
        "            \n",
        "            precision[i], recall[i], threshold_pr = precision_recall_curve(y_true_label[:, i],\n",
        "                                                                y_pred[:, i])\n",
        "\n",
        "            pr_auc = auc(recall[i], precision[i])\n",
        "            pr_auc_list.append(pr_auc)\n",
        "\n",
        "    mean_roc_auc = np.nanmean(roc_auc_list)\n",
        "    mean_pr_auc = np.nanmean(pr_auc_list)\n",
        "\n",
        "    print('mean roc auc',mean_roc_auc)\n",
        "    print('mean pr auc', mean_pr_auc)\n",
        "\n",
        "    return mean_acc, mean_tpr, mean_fpr, mean_precision, mean_roc_auc, mean_pr_auc\n"
      ],
      "metadata": {
        "id": "JcdH860isaKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(self, X_test, y_test, device, batch_size=32):\n",
        "    X_test = torch.as_tensor(X_test, device=device)\n",
        "    y_test = lib.utils.check_numpy(y_test)\n",
        "    self.model.train(False)\n",
        "    with torch.no_grad():\n",
        "        logits = F.softmax(lib.utils.process_in_chunks(self.model, X_test, batch_size=batch_size), dim=1)\n",
        "        logits = lib.utils.check_numpy(logits)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "t4Sy0_M_sg0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lib.Trainer.predict_proba = predict_proba"
      ],
      "metadata": {
        "id": "9aJlmPJZskIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(y)"
      ],
      "metadata": {
        "id": "2WUAiaNsaY8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = set(y_test)\n",
        "classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBXK4Zk6Zj_9",
        "outputId": "89e48492-f805-408f-a25a-d5f3af3fe61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = time.time()\n",
        "y_pred = trainer.predict_proba(x_test, y_test,\n",
        "                                        device=device, batch_size=128)\n",
        "t3 = time.time()\n",
        "inference_time = (t3 - t2) * 1000 / y_test.shape[0]\n",
        "acc_list = []\n",
        "tpr_list = []\n",
        "fpr_list = []\n",
        "precision_list = []\n",
        "roc_auc_list = []\n",
        "pr_auc_list = []\n",
        "training_time_list = []\n",
        "inference_time_list = []\n",
        "cross_val = []\n",
        "\n"
      ],
      "metadata": {
        "id": "_QbgHRkNrQ7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = time.time()\n",
        "y_pred_val = trainer.predict_proba(x_val, y_val,\n",
        "                                        device=device, batch_size=128)\n",
        "t3 = time.time()\n",
        "inference_time = (t3 - t2) * 1000 / y_test.shape[0]\n",
        "acc_list = []\n",
        "tpr_list = []\n",
        "fpr_list = []\n",
        "precision_list = []\n",
        "roc_auc_list = []\n",
        "pr_auc_list = []\n",
        "training_time_list = []\n",
        "inference_time_list = []\n",
        "cross_val = []\n",
        "\n"
      ],
      "metadata": {
        "id": "t7HyUWpPdH9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_pred_val).to_csv(\"data_preds_prob_val.csv\")"
      ],
      "metadata": {
        "id": "eoVntkJ0LFpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SrqoeAOMdy0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_pred).to_csv(\"data_preds_prob_new.csv\")"
      ],
      "metadata": {
        "id": "Ex108g3GDUa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_val).to_csv(\"data_val_new.csv\")"
      ],
      "metadata": {
        "id": "CgXN2vM_doAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test = trainer.loss_function(trainer.model(torch.as_tensor(x_test, device=device)), torch.as_tensor(y_test, device=device)).mean()"
      ],
      "metadata": {
        "id": "_SYL0LNmO2F8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "ecab38f3-2e6f-4c7c-e989-f81671af6e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a58c6ba0535c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlayer_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/nn_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/odst.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# ^--[batch_size, num_trees, depth, 2], approximately binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mbin_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btds,dcs->btdc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin_codes_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# ^--[batch_size, num_trees, depth, 2 ** depth]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 11.17 GiB total capacity; 9.15 GiB already allocated; 1.32 GiB free; 9.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val = trainer.loss_function(trainer.model(torch.as_tensor(x_val, device=device)), torch.as_tensor(y_val, device=device)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "yOrOdNFmCdNC",
        "outputId": "0cc51802-a3e5-4c75-f140-e6664744b787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-dd9d251d9815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlayer_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/nn_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/odst.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# ^--[batch_size, num_trees, depth, 2], approximately binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mbin_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btds,dcs->btdc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin_codes_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# ^--[batch_size, num_trees, depth, 2 ** depth]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.56 GiB (GPU 0; 11.17 GiB total capacity; 9.09 GiB already allocated; 1.32 GiB free; 9.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGQtfPhqPGC6",
        "outputId": "d50772b0-ff08-4224-fa8b-e159b414df02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3995, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val"
      ],
      "metadata": {
        "id": "BjG4R7MrDFQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(folder_path, filename):\n",
        "    df = pd.read_csv(os.path.join(folder_path, filename))\n",
        "    return df"
      ],
      "metadata": {
        "id": "gVH7XGvacCCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_encode(df):\n",
        "    cols_to_encode = list(df.select_dtypes(include=['category','object']))\n",
        "    if len(cols_to_encode): \n",
        "        df = pd.get_dummies(df, columns = cols_to_encode, prefix=cols_to_encode)\n",
        "\n",
        "    return df.values\n"
      ],
      "metadata": {
        "id": "noWRUqOdcFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, target_col=None):\n",
        "    df = df.fillna(df.mean())\n",
        "    if target_col:\n",
        "        X = df.iloc[:, df.columns != target_col]\n",
        "        y = df.loc[:, df.columns == target_col]\n",
        "    else:\n",
        "        X = df.iloc[:, :-1]\n",
        "        y = df.iloc[:, -1]\n",
        "    lb = LabelEncoder()\n",
        "    y = lb.fit_transform(y)\n",
        "    X = dummy_encode(X)\n",
        "    classes = np.unique(y)\n",
        "\n",
        "    return X, y, classes\n"
      ],
      "metadata": {
        "id": "TA5XiM3JcJKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files_list:\n",
        "    print('file', file)\n",
        "\n",
        "    df = read_dataset(files_path, file)\n",
        "\n",
        "    if file == 'analcatdata_germangss.csv':\n",
        "        X, y, classes = prepare_data(df, 'Political_system')\n",
        "    else:\n",
        "        X, y, classes = prepare_data(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0o11DiCcWCz",
        "outputId": "2a7baa8d-565e-47f0-8847-f88935c7ffa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file Churn_Modelling.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g,k,classes = prepare_data(train)"
      ],
      "metadata": {
        "id": "pk48c6qdcWJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open(\"b_file.txt\", \"w\")\n",
        "for element in y_pred:\n",
        "  textfile. write(str(element) + \"\\n\")\n",
        "textfile. close()"
      ],
      "metadata": {
        "id": "Y_4jYSKshkEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK3neib7PrO-",
        "outputId": "90c91cac-46b3-4478-9796-5a052ee39807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "lbg8iK3Ka5Dp",
        "outputId": "af2af2dd-714c-4ff4-bbb4-cf4653333498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-e810c6b431cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlayer_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/nn_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_initialized_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ee5180/node/lib/odst.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# ^--[in_features, num_trees, depth]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mfeature_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bi,ind->bnd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_selectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# ^--[batch_size, num_trees, depth]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 1, but got numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKvKBg5rett3",
        "outputId": "45eadf98-5c4c-4729-ca5f-ab1ae1bdaf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l35cxhQz--lH",
        "outputId": "eddedd2b-aef9-487b-d2e0-288c39153ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_path = '/content/drive/MyDrive/ee5180/node/shrutime'"
      ],
      "metadata": {
        "id": "1mBb0BAMbxHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_label = label_binarize(y_test, classes=classes)"
      ],
      "metadata": {
        "id": "-on64EaGe9dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, mean_tpr, mean_fpr, mean_precision, mean_roc_auc, mean_pr_auc = metrics_calc(y_test, y_pred, classes)\n",
        "\n",
        "acc_list.append(\"{:.3f}\".format(acc))\n",
        "tpr_list.append(\"{:.3f}\".format(mean_tpr))\n",
        "fpr_list.append(\"{:.3f}\".format(mean_fpr))\n",
        "precision_list.append(\"{:.3f}\".format(mean_precision))\n",
        "roc_auc_list.append(\"{:.3f}\".format(mean_roc_auc))\n",
        "pr_auc_list.append(\"{:.3f}\".format(mean_pr_auc))\n",
        "#training_time_list.append(\"{:.1f}\".format(train_time))\n",
        "inference_time_list.append(\"{:.1f}\".format(inference_time))\n",
        "\n",
        "#cross_val.append(fold_num + 1)\n",
        "\n",
        "results_dict = {'Algorithm Name':['node'] * 10,\n",
        "                'Cross Validation':cross_val,\n",
        "                \n",
        "                'Accuracy':acc_list,\n",
        "                'tpr':tpr_list,\n",
        "                'FPR':fpr_list,\n",
        "                'Precision':precision_list,\n",
        "                'AUC':roc_auc_list,\n",
        "                'PR-Curve':pr_auc_list,\n",
        "                'Training Time':training_time_list,\n",
        "                'Inference Time':inference_time_list\n",
        "                }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuUGrIIa2GX",
        "outputId": "42f42a34-b900-4c1c-8496-0742cbfabdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean roc auc 0.8728431446635936\n",
            "mean pr auc 0.695549173223522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbMkW9AkffcS",
        "outputId": "0d32bbdc-ea0a-48cf-a2ed-891bd51ff46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': ['0.873', '0.873'],\n",
              " 'Accuracy': ['0.860', '0.860'],\n",
              " 'Algorithm Name': ['node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node',\n",
              "  'node'],\n",
              " 'Cross Validation': [],\n",
              " 'FPR': ['0.247', '0.247'],\n",
              " 'Inference Time': ['0.1', '0.1'],\n",
              " 'PR-Curve': ['0.696', '0.696'],\n",
              " 'Precision': ['0.785', '0.785'],\n",
              " 'Training Time': [],\n",
              " 'tpr': ['0.753', '0.753']}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uD-SKg74o9Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trials=Trials()\n",
        "#best=fmin(fn=tb_ll_cv, space=reg_params, algo=tpe.suggest, max_evals=10, trials=trials)"
      ],
      "metadata": {
        "id": "pdhZl8NOVL7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "izZAz63EW9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wxRHf7-3W-SH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ee5180_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}