{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shrutime_hyperopt_trial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0y-jubQY3Ge",
        "outputId": "19de50ae-1c47-43d8-dc27-6b8dfbe84d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 18 07:31:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBBzKbfQyuBs",
        "outputId": "b07445a0-109c-4205-9ff2-5c1611176e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GO_hXj_ywv2",
        "outputId": "839ca8d1-3986-4bb9-f78e-7cd757d85e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  test_shrutime.csv\ttrain_shrutime.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRRrz8z3zAnj",
        "outputId": "10d57ded-46be-465c-ff65-0690d5d4afbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import gzip\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "bCdVg4CXzQIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train_shrutime.csv')\n",
        "n_total = len(df)\n",
        "\n",
        "# Train, val and test split follows\n",
        "# Rory Mitchell, Andrey Adinets, Thejaswi Rao, and Eibe Frank.\n",
        "# Xgboost: Scalable GPU accelerated learning. arXiv:1806.11248, 2018.\n",
        "\n",
        "# train_val_indices, test_indices = train_test_split(\n",
        "#     range(n_total), test_size=0.2, random_state=0)\n",
        "# train_indices, val_indices = train_test_split(\n",
        "#     train_val_indices, test_size=0.2 / 0.6, random_state=0)\n",
        "\n",
        "# traindf = df.iloc[train_indices]\n",
        "# valdf = df.iloc[val_indices]\n",
        "# testdf = df.iloc[test_indices]\n",
        "# traindf = traindf.sample(frac=1)\n",
        "\n",
        "# traindf.to_csv('train_shrutime.csv', index=False, header=False)\n",
        "# valdf.to_csv('val_shrutime.csv', index=False, header=False)\n",
        "# testdf.to_csv('test_shrutime.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "2M3nn9LATDBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('test_shrutime.csv')"
      ],
      "metadata": {
        "id": "97WPRbJPl_Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        l = [0 for i in range(7)]\n",
        "        l[y[i] - 1] = 1\n",
        "        if not seen:\n",
        "            y_o = np.array(l.copy())\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, l.copy()])\n",
        "    return y_o\n",
        "# data = pd.read_csv(input_dir + 'Churn_Modelling.csv')\n",
        "# data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n",
        "\n",
        "\n",
        "def convert_country(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        if not seen:\n",
        "            y_o = np.array([m1[y[i]]])\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, [m1[y[i]]]])\n",
        "    return y_o\n",
        "\n",
        "def convert_gender(y):\n",
        "    seen = False\n",
        "    for i in range(len(y)):\n",
        "        if not seen:\n",
        "            y_o = np.array([m2[y[i]]])\n",
        "            seen = True\n",
        "        else:\n",
        "            y_o = np.vstack([y_o, [m2[y[i]]]])\n",
        "    return y_o\n",
        "    \n"
      ],
      "metadata": {
        "id": "RAqSYqtX_tu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fast_ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jg0TKPVBsn8",
        "outputId": "82b966c4-ceba-461e-8a09-e8284636ffc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 30 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 833 kB/s \n",
            "\u001b[?25hInstalling collected packages: fast-ml\n",
            "Successfully installed fast-ml-3.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6dq9JWT1nEt2",
        "outputId": "bb343561-8610-4644-fc6d-d3f1b9602270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          708   67       1       0.00              2          0   \n",
              "1          603   35       1  123407.69              1          1   \n",
              "2          618   33       4       0.00              2          1   \n",
              "3          592   37       9       0.00              3          1   \n",
              "4          517   59       8  154110.99              2          1   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  Geography  Gender  \n",
              "0               1          3837.08       0          0       1  \n",
              "1               0        152541.89       1          2       0  \n",
              "2               1         77550.18       0          1       0  \n",
              "3               1         10656.89       0          1       0  \n",
              "4               0        101240.08       1          2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffa16507-c797-44e0-8686-b652f477a59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>708</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3837.08</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>603</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>123407.69</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152541.89</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>618</td>\n",
              "      <td>33</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>77550.18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>592</td>\n",
              "      <td>37</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10656.89</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>517</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>154110.99</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>101240.08</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffa16507-c797-44e0-8686-b652f477a59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffa16507-c797-44e0-8686-b652f477a59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffa16507-c797-44e0-8686-b652f477a59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = {\"France\" : 0, \"Spain\" : 1, \"Germany\" : 2}\n",
        "m2 = {\"Male\" : 0, \"Female\" : 1}\n",
        "\n",
        "# y = df[\"Geography\"]\n",
        "# y = y.to_numpy()\n",
        "# y = convert_country(y)\n",
        "# df = df.drop(\"Geography\", axis = 1)\n",
        "# df[\"Geography\"] = y\n",
        "\n",
        "# y = df[\"Gender\"]\n",
        "# y = y.to_numpy()\n",
        "# y = convert_gender(y)\n",
        "# df = df.drop(\"Gender\", axis = 1)\n",
        "y=df[\"Exited\"]\n",
        "y_test=test_df[\"Exited\"]\n",
        "df = df.drop(\"Exited\", axis = 1)\n",
        "test_df = test_df.drop(\"Exited\", axis = 1)\n",
        "# y_test = test_df[\"Geography\"]\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = convert_country(y_test)\n",
        "# test_df = test_df.drop(\"Geography\", axis = 1)\n",
        "# test_df[\"Geography\"] = y_test\n",
        "\n",
        "# y_test = test_df[\"Gender\"]\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = convert_gender(y_test)\n",
        "# test_df = test_df.drop(\"Gender\", axis = 1)\n",
        "# test_df[\"Gender\"] = y_test\n",
        "# print(test_df.shape)\n",
        "\n",
        "# x_train = train.drop(\"Cover_Type\", axis = 1)\n",
        "# y_train = train[train.columns[-1]]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(df,y,train_size=0.9)\n",
        "\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "#y_train = np.expand_dims(y_train, axis=1)\n",
        "#y_train = convert_to_one_hot(y_train)\n",
        "\n",
        "\n",
        "x_valid = x_valid.to_numpy()\n",
        "y_valid = y_valid.to_numpy()\n",
        "#y_valid = np.expand_dims(y_valid, axis=1)\n",
        "#y_valid = convert_to_one_hot(y_valid)\n",
        "\n",
        "x_test = test_df.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "#y_test = np.expand_dims(y_test, axis=1)\n",
        "#y_test = convert_to_one_hot(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_valid.shape)\n",
        "print(y_valid.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "print(df.shape)\n",
        "y = df[df.columns[-1]]\n",
        "y = y.to_numpy()\n",
        "target_cols = [\"Exited\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwru7dsnBUWU",
        "outputId": "463a391b-a0b8-4eef-b863-7b5c0ff5ef82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7200, 10)\n",
            "(7200,)\n",
            "(800, 10)\n",
            "(800,)\n",
            "(2000, 10)\n",
            "(2000,)\n",
            "(8000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rrKTRgTfTsJX",
        "outputId": "d97ef775-7759-4cc2-abdb-c5cb619daa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          708   67       1       0.00              2          0   \n",
              "1          603   35       1  123407.69              1          1   \n",
              "2          618   33       4       0.00              2          1   \n",
              "3          592   37       9       0.00              3          1   \n",
              "4          517   59       8  154110.99              2          1   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Geography  Gender  \n",
              "0               1          3837.08          0       1  \n",
              "1               0        152541.89          2       0  \n",
              "2               1         77550.18          1       0  \n",
              "3               1         10656.89          1       0  \n",
              "4               0        101240.08          2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbce22a2-3bb9-46cf-886c-97955af73ae2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>708</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3837.08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>603</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>123407.69</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152541.89</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>618</td>\n",
              "      <td>33</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>77550.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>592</td>\n",
              "      <td>37</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10656.89</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>517</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>154110.99</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>101240.08</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbce22a2-3bb9-46cf-886c-97955af73ae2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbce22a2-3bb9-46cf-886c-97955af73ae2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbce22a2-3bb9-46cf-886c-97955af73ae2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puD661w-E2Ku",
        "outputId": "d223122f-6dbe-43ca-ecf2-51cd61de9263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.2600000e+02, 3.9000000e+01, 1.0000000e+01, ..., 5.1467920e+04,\n",
              "        2.0000000e+00, 0.0000000e+00],\n",
              "       [7.4800000e+02, 4.0000000e+01, 0.0000000e+00, ..., 6.0416760e+04,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [7.8600000e+02, 3.4000000e+01, 3.0000000e+00, ..., 1.8368209e+05,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       ...,\n",
              "       [5.8100000e+02, 5.0000000e+01, 4.0000000e+00, ..., 8.0701720e+04,\n",
              "        1.0000000e+00, 1.0000000e+00],\n",
              "       [6.4500000e+02, 4.5000000e+01, 8.0000000e+00, ..., 2.2558740e+04,\n",
              "        0.0000000e+00, 1.0000000e+00],\n",
              "       [5.7300000e+02, 3.7000000e+01, 6.0000000e+00, ..., 1.9399537e+05,\n",
              "        0.0000000e+00, 1.0000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNAtrbgJFHiT",
        "outputId": "e38c7df9-0152-44ed-8569-c47fd758deb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
      ],
      "metadata": {
        "id": "4cQIPit30rxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import hp"
      ],
      "metadata": {
        "id": "ehT6opIV1Hcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperopt"
      ],
      "metadata": {
        "id": "LFYiZ_cP1Tv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "from hyperopt import fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
        "from hyperopt.pyll.base import scope\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "omqi0I5u1Uvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "tsONlCvzXTR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tb_ll_cv(space):\n",
        "  #print(\"hello\")\n",
        "  model=TabNetClassifier(n_a=int(space['n_a']), n_d=int(space['n_a']), n_steps=int(space['n_steps']), momentum=space['momentum'], gamma=space['gamma'], optimizer_params=dict(lr=space['lr']), device_name='cuda')\n",
        "  model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], batch_size=int(space['batch_size']),max_epochs=100,eval_metric=['logloss'])\n",
        "  #print(model.history[\"val_0_logloss\"])\n",
        "  return min(model.history[\"val_0_logloss\"])\n"
      ],
      "metadata": {
        "id": "7yrQ0_k5IBnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_params = {'n_a': hp.quniform('feature_dim', 20, 60, 1),'n_steps': hp.quniform('n_steps', 1, 8, 1),'momentum': hp.uniform('momentum', np.exp(-5), np.exp(-1)),'gamma': hp.uniform('relaxation_factor', 0.3, 2),\n",
        "    'batch_size': hp.choice('batch_size',[512, 1024, 2048, 4096, 8192]), 'lr':hp.loguniform('learning_rate', -5, 0)\n",
        "}"
      ],
      "metadata": {
        "id": "JijpC5Xt1Yib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials=Trials()\n",
        "best=fmin(fn=tb_ll_cv, space=reg_params, algo=tpe.suggest, max_evals=15, trials=trials)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MF2xcftPs66",
        "outputId": "8d7d1b54-f7b3-467a-ea6b-6b265da3dcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 3.2162  | val_0_logloss: 3.99704 |  0:00:00s\n",
            "epoch 1  | loss: 0.60427 | val_0_logloss: 1.85831 |  0:00:01s\n",
            "epoch 2  | loss: 0.54808 | val_0_logloss: 0.70269 |  0:00:01s\n",
            "epoch 3  | loss: 0.52125 | val_0_logloss: 0.88212 |  0:00:02s\n",
            "epoch 4  | loss: 0.47213 | val_0_logloss: 0.81193 |  0:00:03s\n",
            "epoch 5  | loss: 0.45997 | val_0_logloss: 0.9907  |  0:00:03s\n",
            "epoch 6  | loss: 0.43664 | val_0_logloss: 0.86119 |  0:00:04s\n",
            "epoch 7  | loss: 0.44199 | val_0_logloss: 1.63431 |  0:00:04s\n",
            "epoch 8  | loss: 0.45031 | val_0_logloss: 1.52461 |  0:00:05s\n",
            "epoch 9  | loss: 0.42584 | val_0_logloss: 1.6097  |  0:00:05s\n",
            "epoch 10 | loss: 0.41859 | val_0_logloss: 0.59092 |  0:00:06s\n",
            "epoch 11 | loss: 0.41197 | val_0_logloss: 0.66818 |  0:00:07s\n",
            "epoch 12 | loss: 0.411   | val_0_logloss: 0.86109 |  0:00:07s\n",
            "epoch 13 | loss: 0.4114  | val_0_logloss: 0.51552 |  0:00:08s\n",
            "epoch 14 | loss: 0.41349 | val_0_logloss: 0.63898 |  0:00:08s\n",
            "epoch 15 | loss: 0.41389 | val_0_logloss: 0.59316 |  0:00:09s\n",
            "epoch 16 | loss: 0.41252 | val_0_logloss: 0.51422 |  0:00:09s\n",
            "epoch 17 | loss: 0.40248 | val_0_logloss: 0.44771 |  0:00:10s\n",
            "epoch 18 | loss: 0.39547 | val_0_logloss: 0.47359 |  0:00:11s\n",
            "epoch 19 | loss: 0.3981  | val_0_logloss: 0.41637 |  0:00:11s\n",
            "epoch 20 | loss: 0.40199 | val_0_logloss: 0.42267 |  0:00:12s\n",
            "epoch 21 | loss: 0.40125 | val_0_logloss: 0.48022 |  0:00:12s\n",
            "epoch 22 | loss: 0.41439 | val_0_logloss: 0.43614 |  0:00:13s\n",
            "epoch 23 | loss: 0.39799 | val_0_logloss: 0.42081 |  0:00:14s\n",
            "epoch 24 | loss: 0.39812 | val_0_logloss: 0.39431 |  0:00:14s\n",
            "epoch 25 | loss: 0.39838 | val_0_logloss: 0.39925 |  0:00:15s\n",
            "epoch 26 | loss: 0.3961  | val_0_logloss: 0.39522 |  0:00:15s\n",
            "epoch 27 | loss: 0.40003 | val_0_logloss: 0.41023 |  0:00:16s\n",
            "epoch 28 | loss: 0.40011 | val_0_logloss: 0.39112 |  0:00:16s\n",
            "epoch 29 | loss: 0.40014 | val_0_logloss: 0.4223  |  0:00:17s\n",
            "epoch 30 | loss: 0.40564 | val_0_logloss: 0.46088 |  0:00:18s\n",
            "epoch 31 | loss: 0.40701 | val_0_logloss: 0.39042 |  0:00:18s\n",
            "epoch 32 | loss: 0.39426 | val_0_logloss: 0.84322 |  0:00:19s\n",
            "epoch 33 | loss: 0.3969  | val_0_logloss: 0.37891 |  0:00:19s\n",
            "epoch 34 | loss: 0.39239 | val_0_logloss: 0.38745 |  0:00:20s\n",
            "epoch 35 | loss: 0.40021 | val_0_logloss: 0.35891 |  0:00:21s\n",
            "epoch 36 | loss: 0.38243 | val_0_logloss: 0.43141 |  0:00:21s\n",
            "epoch 37 | loss: 0.40248 | val_0_logloss: 0.38366 |  0:00:22s\n",
            "epoch 38 | loss: 0.38813 | val_0_logloss: 0.37878 |  0:00:22s\n",
            "epoch 39 | loss: 0.3894  | val_0_logloss: 0.372   |  0:00:23s\n",
            "epoch 40 | loss: 0.3887  | val_0_logloss: 0.37439 |  0:00:23s\n",
            "epoch 41 | loss: 0.39065 | val_0_logloss: 0.37525 |  0:00:24s\n",
            "epoch 42 | loss: 0.38782 | val_0_logloss: 0.37703 |  0:00:25s\n",
            "epoch 43 | loss: 0.38659 | val_0_logloss: 0.82263 |  0:00:25s\n",
            "epoch 44 | loss: 0.42881 | val_0_logloss: 0.3506  |  0:00:26s\n",
            "epoch 45 | loss: 0.37772 | val_0_logloss: 0.52625 |  0:00:26s\n",
            "epoch 46 | loss: 0.40993 | val_0_logloss: 0.36577 |  0:00:27s\n",
            "epoch 47 | loss: 0.41281 | val_0_logloss: 0.35588 |  0:00:28s\n",
            "epoch 48 | loss: 0.3668  | val_0_logloss: 0.35112 |  0:00:28s\n",
            "epoch 49 | loss: 0.3754  | val_0_logloss: 0.37486 |  0:00:29s\n",
            "epoch 50 | loss: 0.38194 | val_0_logloss: 0.46702 |  0:00:29s\n",
            "epoch 51 | loss: 0.36457 | val_0_logloss: 0.35283 |  0:00:30s\n",
            "epoch 52 | loss: 0.37745 | val_0_logloss: 0.33885 |  0:00:30s\n",
            "epoch 53 | loss: 0.38317 | val_0_logloss: 0.3652  |  0:00:31s\n",
            "epoch 54 | loss: 0.3676  | val_0_logloss: 0.34234 |  0:00:32s\n",
            "epoch 55 | loss: 0.36716 | val_0_logloss: 0.34742 |  0:00:32s\n",
            "epoch 56 | loss: 0.36799 | val_0_logloss: 0.34764 |  0:00:33s\n",
            "epoch 57 | loss: 0.37556 | val_0_logloss: 0.34278 |  0:00:33s\n",
            "epoch 58 | loss: 0.37907 | val_0_logloss: 0.3581  |  0:00:34s\n",
            "epoch 59 | loss: 0.36875 | val_0_logloss: 0.34608 |  0:00:34s\n",
            "epoch 60 | loss: 0.37331 | val_0_logloss: 0.36818 |  0:00:35s\n",
            "epoch 61 | loss: 0.40166 | val_0_logloss: 0.3654  |  0:00:36s\n",
            "epoch 62 | loss: 0.37179 | val_0_logloss: 0.34852 |  0:00:36s\n",
            "\n",
            "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_logloss = 0.33885\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 23.76849| val_0_logloss: 17.88775|  0:00:00s\n",
            "epoch 1  | loss: 18.20822| val_0_logloss: 20.98632|  0:00:01s\n",
            "epoch 2  | loss: 4.83136 | val_0_logloss: 26.5958 |  0:00:02s\n",
            "epoch 3  | loss: 0.97401 | val_0_logloss: 17.4435 |  0:00:02s\n",
            "epoch 4  | loss: 0.73409 | val_0_logloss: 17.70582|  0:00:03s\n",
            "epoch 5  | loss: 0.69386 | val_0_logloss: 7.07483 |  0:00:04s\n",
            "epoch 6  | loss: 0.49209 | val_0_logloss: 3.13799 |  0:00:04s\n",
            "epoch 7  | loss: 0.42711 | val_0_logloss: 4.11577 |  0:00:05s\n",
            "epoch 8  | loss: 0.4235  | val_0_logloss: 4.29665 |  0:00:06s\n",
            "epoch 9  | loss: 0.40415 | val_0_logloss: 3.45258 |  0:00:06s\n",
            "epoch 10 | loss: 0.39442 | val_0_logloss: 3.42426 |  0:00:07s\n",
            "epoch 11 | loss: 0.38589 | val_0_logloss: 3.04809 |  0:00:08s\n",
            "epoch 12 | loss: 0.38004 | val_0_logloss: 2.97569 |  0:00:08s\n",
            "epoch 13 | loss: 0.37955 | val_0_logloss: 1.51958 |  0:00:09s\n",
            "epoch 14 | loss: 0.4005  | val_0_logloss: 1.11655 |  0:00:10s\n",
            "epoch 15 | loss: 0.39266 | val_0_logloss: 1.65526 |  0:00:11s\n",
            "epoch 16 | loss: 0.40108 | val_0_logloss: 1.34255 |  0:00:11s\n",
            "epoch 17 | loss: 0.37858 | val_0_logloss: 1.03582 |  0:00:12s\n",
            "epoch 18 | loss: 0.38805 | val_0_logloss: 0.97994 |  0:00:13s\n",
            "epoch 19 | loss: 0.37965 | val_0_logloss: 0.94162 |  0:00:13s\n",
            "epoch 20 | loss: 0.37612 | val_0_logloss: 0.71808 |  0:00:14s\n",
            "epoch 21 | loss: 0.37348 | val_0_logloss: 0.73378 |  0:00:15s\n",
            "epoch 22 | loss: 0.37334 | val_0_logloss: 1.05343 |  0:00:15s\n",
            "epoch 23 | loss: 0.3682  | val_0_logloss: 0.77466 |  0:00:16s\n",
            "epoch 24 | loss: 0.3686  | val_0_logloss: 0.72627 |  0:00:17s\n",
            "epoch 25 | loss: 0.3687  | val_0_logloss: 0.63778 |  0:00:18s\n",
            "epoch 26 | loss: 0.36491 | val_0_logloss: 0.60682 |  0:00:18s\n",
            "epoch 27 | loss: 0.36593 | val_0_logloss: 0.62508 |  0:00:19s\n",
            "epoch 28 | loss: 0.36243 | val_0_logloss: 0.55185 |  0:00:20s\n",
            "epoch 29 | loss: 0.36358 | val_0_logloss: 0.56988 |  0:00:20s\n",
            "epoch 30 | loss: 0.36333 | val_0_logloss: 0.57032 |  0:00:21s\n",
            "epoch 31 | loss: 0.36283 | val_0_logloss: 0.55442 |  0:00:22s\n",
            "epoch 32 | loss: 0.36081 | val_0_logloss: 0.51432 |  0:00:23s\n",
            "epoch 33 | loss: 0.36115 | val_0_logloss: 0.54664 |  0:00:23s\n",
            "epoch 34 | loss: 0.36093 | val_0_logloss: 0.51068 |  0:00:24s\n",
            "epoch 35 | loss: 0.36595 | val_0_logloss: 0.45651 |  0:00:25s\n",
            "epoch 36 | loss: 0.37441 | val_0_logloss: 0.42226 |  0:00:25s\n",
            "epoch 37 | loss: 0.36321 | val_0_logloss: 0.43291 |  0:00:26s\n",
            "epoch 38 | loss: 0.36665 | val_0_logloss: 0.43013 |  0:00:27s\n",
            "epoch 39 | loss: 0.36587 | val_0_logloss: 0.39844 |  0:00:27s\n",
            "epoch 40 | loss: 0.3754  | val_0_logloss: 0.41718 |  0:00:28s\n",
            "epoch 41 | loss: 0.38571 | val_0_logloss: 0.38638 |  0:00:29s\n",
            "epoch 42 | loss: 0.3767  | val_0_logloss: 0.52351 |  0:00:29s\n",
            "epoch 43 | loss: 0.38057 | val_0_logloss: 0.43008 |  0:00:30s\n",
            "epoch 44 | loss: 0.39151 | val_0_logloss: 0.72846 |  0:00:31s\n",
            "epoch 45 | loss: 0.45351 | val_0_logloss: 0.41639 |  0:00:32s\n",
            "epoch 46 | loss: 0.4098  | val_0_logloss: 0.54478 |  0:00:32s\n",
            "epoch 47 | loss: 0.42674 | val_0_logloss: 0.50659 |  0:00:33s\n",
            "epoch 48 | loss: 0.41401 | val_0_logloss: 1.08091 |  0:00:34s\n",
            "epoch 49 | loss: 0.40943 | val_0_logloss: 0.51536 |  0:00:34s\n",
            "epoch 50 | loss: 0.40074 | val_0_logloss: 0.88135 |  0:00:35s\n",
            "epoch 51 | loss: 0.40675 | val_0_logloss: 0.44254 |  0:00:36s\n",
            "\n",
            "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_logloss = 0.38638\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 3.21341 | val_0_logloss: 18.31669|  0:00:00s\n",
            "epoch 1  | loss: 0.85052 | val_0_logloss: 11.21561|  0:00:01s\n",
            "epoch 2  | loss: 0.49563 | val_0_logloss: 22.42464|  0:00:01s\n",
            "epoch 3  | loss: 0.40798 | val_0_logloss: 12.37388|  0:00:02s\n",
            "epoch 4  | loss: 0.36445 | val_0_logloss: 5.81869 |  0:00:02s\n",
            "epoch 5  | loss: 0.35222 | val_0_logloss: 8.47738 |  0:00:03s\n",
            "epoch 6  | loss: 0.34219 | val_0_logloss: 4.88917 |  0:00:04s\n",
            "epoch 7  | loss: 0.33234 | val_0_logloss: 5.584   |  0:00:04s\n",
            "epoch 8  | loss: 0.3291  | val_0_logloss: 3.84275 |  0:00:05s\n",
            "epoch 9  | loss: 0.31831 | val_0_logloss: 2.8022  |  0:00:05s\n",
            "epoch 10 | loss: 0.31837 | val_0_logloss: 2.51763 |  0:00:06s\n",
            "epoch 11 | loss: 0.31213 | val_0_logloss: 2.25753 |  0:00:07s\n",
            "epoch 12 | loss: 0.31111 | val_0_logloss: 2.35128 |  0:00:07s\n",
            "epoch 13 | loss: 0.30552 | val_0_logloss: 2.9151  |  0:00:08s\n",
            "epoch 14 | loss: 0.30575 | val_0_logloss: 2.18248 |  0:00:08s\n",
            "epoch 15 | loss: 0.30169 | val_0_logloss: 2.05053 |  0:00:09s\n",
            "epoch 16 | loss: 0.29779 | val_0_logloss: 1.71833 |  0:00:09s\n",
            "epoch 17 | loss: 0.2962  | val_0_logloss: 1.68143 |  0:00:10s\n",
            "epoch 18 | loss: 0.29344 | val_0_logloss: 1.6325  |  0:00:11s\n",
            "epoch 19 | loss: 0.28991 | val_0_logloss: 1.48483 |  0:00:11s\n",
            "epoch 20 | loss: 0.28408 | val_0_logloss: 1.41322 |  0:00:12s\n",
            "epoch 21 | loss: 0.28431 | val_0_logloss: 1.56021 |  0:00:12s\n",
            "epoch 22 | loss: 0.28214 | val_0_logloss: 1.58619 |  0:00:13s\n",
            "epoch 23 | loss: 0.278   | val_0_logloss: 1.39132 |  0:00:14s\n",
            "epoch 24 | loss: 0.2725  | val_0_logloss: 1.52229 |  0:00:14s\n",
            "epoch 25 | loss: 0.27004 | val_0_logloss: 1.54074 |  0:00:15s\n",
            "epoch 26 | loss: 0.26886 | val_0_logloss: 1.57278 |  0:00:15s\n",
            "epoch 27 | loss: 0.26468 | val_0_logloss: 1.55142 |  0:00:16s\n",
            "epoch 28 | loss: 0.25821 | val_0_logloss: 1.54151 |  0:00:17s\n",
            "epoch 29 | loss: 0.25707 | val_0_logloss: 1.59723 |  0:00:17s\n",
            "epoch 30 | loss: 0.25086 | val_0_logloss: 1.64809 |  0:00:18s\n",
            "epoch 31 | loss: 0.24834 | val_0_logloss: 1.63873 |  0:00:18s\n",
            "epoch 32 | loss: 0.24416 | val_0_logloss: 1.5645  |  0:00:19s\n",
            "epoch 33 | loss: 0.23825 | val_0_logloss: 1.79217 |  0:00:20s\n",
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 1.39132\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 2.07098 | val_0_logloss: 14.85877|  0:00:00s\n",
            "epoch 1  | loss: 0.82168 | val_0_logloss: 12.80217|  0:00:01s\n",
            "epoch 2  | loss: 0.6396  | val_0_logloss: 14.14862|  0:00:01s\n",
            "epoch 3  | loss: 0.60736 | val_0_logloss: 11.43377|  0:00:02s\n",
            "epoch 4  | loss: 0.51071 | val_0_logloss: 9.15957 |  0:00:02s\n",
            "epoch 5  | loss: 0.4748  | val_0_logloss: 9.35606 |  0:00:03s\n",
            "epoch 6  | loss: 0.44217 | val_0_logloss: 7.76286 |  0:00:03s\n",
            "epoch 7  | loss: 0.41837 | val_0_logloss: 8.05266 |  0:00:04s\n",
            "epoch 8  | loss: 0.39775 | val_0_logloss: 7.37308 |  0:00:04s\n",
            "epoch 9  | loss: 0.38703 | val_0_logloss: 6.59743 |  0:00:05s\n",
            "epoch 10 | loss: 0.36812 | val_0_logloss: 6.69829 |  0:00:06s\n",
            "epoch 11 | loss: 0.3595  | val_0_logloss: 6.3194  |  0:00:06s\n",
            "epoch 12 | loss: 0.35392 | val_0_logloss: 6.53003 |  0:00:07s\n",
            "epoch 13 | loss: 0.34928 | val_0_logloss: 6.61413 |  0:00:07s\n",
            "epoch 14 | loss: 0.3344  | val_0_logloss: 6.19855 |  0:00:08s\n",
            "epoch 15 | loss: 0.33578 | val_0_logloss: 6.15057 |  0:00:08s\n",
            "epoch 16 | loss: 0.33117 | val_0_logloss: 6.39659 |  0:00:09s\n",
            "epoch 17 | loss: 0.32329 | val_0_logloss: 5.83805 |  0:00:09s\n",
            "epoch 18 | loss: 0.32164 | val_0_logloss: 5.90401 |  0:00:10s\n",
            "epoch 19 | loss: 0.31287 | val_0_logloss: 6.12372 |  0:00:10s\n",
            "epoch 20 | loss: 0.30974 | val_0_logloss: 5.49438 |  0:00:11s\n",
            "epoch 21 | loss: 0.30889 | val_0_logloss: 5.52487 |  0:00:12s\n",
            "epoch 22 | loss: 0.30212 | val_0_logloss: 4.93584 |  0:00:12s\n",
            "epoch 23 | loss: 0.29999 | val_0_logloss: 5.08319 |  0:00:13s\n",
            "epoch 24 | loss: 0.29586 | val_0_logloss: 4.82215 |  0:00:13s\n",
            "epoch 25 | loss: 0.29237 | val_0_logloss: 4.45836 |  0:00:14s\n",
            "epoch 26 | loss: 0.28906 | val_0_logloss: 4.36864 |  0:00:14s\n",
            "epoch 27 | loss: 0.28687 | val_0_logloss: 4.1884  |  0:00:15s\n",
            "epoch 28 | loss: 0.28413 | val_0_logloss: 3.73229 |  0:00:15s\n",
            "epoch 29 | loss: 0.27969 | val_0_logloss: 4.07078 |  0:00:16s\n",
            "epoch 30 | loss: 0.27658 | val_0_logloss: 3.86695 |  0:00:16s\n",
            "epoch 31 | loss: 0.27689 | val_0_logloss: 3.57426 |  0:00:17s\n",
            "epoch 32 | loss: 0.27762 | val_0_logloss: 3.71611 |  0:00:18s\n",
            "epoch 33 | loss: 0.27329 | val_0_logloss: 3.20726 |  0:00:18s\n",
            "epoch 34 | loss: 0.26978 | val_0_logloss: 3.46586 |  0:00:19s\n",
            "epoch 35 | loss: 0.26972 | val_0_logloss: 3.46701 |  0:00:19s\n",
            "epoch 36 | loss: 0.26452 | val_0_logloss: 3.08189 |  0:00:20s\n",
            "epoch 37 | loss: 0.26033 | val_0_logloss: 3.06741 |  0:00:20s\n",
            "epoch 38 | loss: 0.26509 | val_0_logloss: 3.24737 |  0:00:21s\n",
            "epoch 39 | loss: 0.25775 | val_0_logloss: 3.20893 |  0:00:21s\n",
            "epoch 40 | loss: 0.25882 | val_0_logloss: 2.97584 |  0:00:22s\n",
            "epoch 41 | loss: 0.25564 | val_0_logloss: 2.88251 |  0:00:23s\n",
            "epoch 42 | loss: 0.25751 | val_0_logloss: 3.0272  |  0:00:23s\n",
            "epoch 43 | loss: 0.25174 | val_0_logloss: 3.07259 |  0:00:24s\n",
            "epoch 44 | loss: 0.25271 | val_0_logloss: 2.98723 |  0:00:24s\n",
            "epoch 45 | loss: 0.24781 | val_0_logloss: 2.87125 |  0:00:25s\n",
            "epoch 46 | loss: 0.2465  | val_0_logloss: 2.84784 |  0:00:25s\n",
            "epoch 47 | loss: 0.24657 | val_0_logloss: 2.6758  |  0:00:26s\n",
            "epoch 48 | loss: 0.24389 | val_0_logloss: 2.7683  |  0:00:26s\n",
            "epoch 49 | loss: 0.24415 | val_0_logloss: 2.60298 |  0:00:27s\n",
            "epoch 50 | loss: 0.23834 | val_0_logloss: 2.55207 |  0:00:27s\n",
            "epoch 51 | loss: 0.2357  | val_0_logloss: 2.62193 |  0:00:28s\n",
            "epoch 52 | loss: 0.24055 | val_0_logloss: 2.5242  |  0:00:28s\n",
            "epoch 53 | loss: 0.23444 | val_0_logloss: 2.68348 |  0:00:29s\n",
            "epoch 54 | loss: 0.23335 | val_0_logloss: 2.53448 |  0:00:30s\n",
            "epoch 55 | loss: 0.23361 | val_0_logloss: 2.41791 |  0:00:30s\n",
            "epoch 56 | loss: 0.23171 | val_0_logloss: 2.56036 |  0:00:31s\n",
            "epoch 57 | loss: 0.23054 | val_0_logloss: 2.41799 |  0:00:31s\n",
            "epoch 58 | loss: 0.22888 | val_0_logloss: 2.31343 |  0:00:32s\n",
            "epoch 59 | loss: 0.23143 | val_0_logloss: 2.37264 |  0:00:32s\n",
            "epoch 60 | loss: 0.22291 | val_0_logloss: 2.28096 |  0:00:33s\n",
            "epoch 61 | loss: 0.22487 | val_0_logloss: 2.26364 |  0:00:33s\n",
            "epoch 62 | loss: 0.2204  | val_0_logloss: 2.32903 |  0:00:34s\n",
            "epoch 63 | loss: 0.22054 | val_0_logloss: 2.31443 |  0:00:35s\n",
            "epoch 64 | loss: 0.22003 | val_0_logloss: 2.31264 |  0:00:35s\n",
            "epoch 65 | loss: 0.2183  | val_0_logloss: 2.29603 |  0:00:36s\n",
            "epoch 66 | loss: 0.21679 | val_0_logloss: 2.20744 |  0:00:36s\n",
            "epoch 67 | loss: 0.21458 | val_0_logloss: 2.20424 |  0:00:37s\n",
            "epoch 68 | loss: 0.2122  | val_0_logloss: 2.18951 |  0:00:37s\n",
            "epoch 69 | loss: 0.20921 | val_0_logloss: 2.17719 |  0:00:38s\n",
            "epoch 70 | loss: 0.21224 | val_0_logloss: 2.09218 |  0:00:38s\n",
            "epoch 71 | loss: 0.20624 | val_0_logloss: 2.10716 |  0:00:39s\n",
            "epoch 72 | loss: 0.20347 | val_0_logloss: 2.02186 |  0:00:39s\n",
            "epoch 73 | loss: 0.20055 | val_0_logloss: 2.0513  |  0:00:40s\n",
            "epoch 74 | loss: 0.20328 | val_0_logloss: 1.98571 |  0:00:41s\n",
            "epoch 75 | loss: 0.20429 | val_0_logloss: 1.96293 |  0:00:41s\n",
            "epoch 76 | loss: 0.20197 | val_0_logloss: 1.97689 |  0:00:42s\n",
            "epoch 77 | loss: 0.19872 | val_0_logloss: 2.0169  |  0:00:42s\n",
            "epoch 78 | loss: 0.19576 | val_0_logloss: 2.01314 |  0:00:43s\n",
            "epoch 79 | loss: 0.19471 | val_0_logloss: 1.99024 |  0:00:43s\n",
            "epoch 80 | loss: 0.19132 | val_0_logloss: 2.02259 |  0:00:44s\n",
            "epoch 81 | loss: 0.19575 | val_0_logloss: 1.94783 |  0:00:44s\n",
            "epoch 82 | loss: 0.19157 | val_0_logloss: 2.0741  |  0:00:45s\n",
            "epoch 83 | loss: 0.19292 | val_0_logloss: 1.98156 |  0:00:45s\n",
            "epoch 84 | loss: 0.18863 | val_0_logloss: 1.99847 |  0:00:46s\n",
            "epoch 85 | loss: 0.18837 | val_0_logloss: 1.92612 |  0:00:46s\n",
            "epoch 86 | loss: 0.18306 | val_0_logloss: 1.86638 |  0:00:47s\n",
            "epoch 87 | loss: 0.18206 | val_0_logloss: 1.91298 |  0:00:47s\n",
            "epoch 88 | loss: 0.18218 | val_0_logloss: 1.88941 |  0:00:48s\n",
            "epoch 89 | loss: 0.18361 | val_0_logloss: 1.86618 |  0:00:49s\n",
            "epoch 90 | loss: 0.17831 | val_0_logloss: 1.87519 |  0:00:49s\n",
            "epoch 91 | loss: 0.17763 | val_0_logloss: 1.82159 |  0:00:50s\n",
            "epoch 92 | loss: 0.1802  | val_0_logloss: 1.81032 |  0:00:50s\n",
            "epoch 93 | loss: 0.18031 | val_0_logloss: 1.63779 |  0:00:51s\n",
            "epoch 94 | loss: 0.1739  | val_0_logloss: 1.6628  |  0:00:51s\n",
            "epoch 95 | loss: 0.17451 | val_0_logloss: 1.6674  |  0:00:52s\n",
            "epoch 96 | loss: 0.17415 | val_0_logloss: 1.6518  |  0:00:52s\n",
            "epoch 97 | loss: 0.16988 | val_0_logloss: 1.59264 |  0:00:53s\n",
            "epoch 98 | loss: 0.16953 | val_0_logloss: 1.71947 |  0:00:53s\n",
            "epoch 99 | loss: 0.17335 | val_0_logloss: 1.69884 |  0:00:54s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_logloss = 1.59264\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 1.32866 | val_0_logloss: 7.23442 |  0:00:00s\n",
            "epoch 1  | loss: 0.46026 | val_0_logloss: 2.56568 |  0:00:01s\n",
            "epoch 2  | loss: 0.45513 | val_0_logloss: 1.77834 |  0:00:01s\n",
            "epoch 3  | loss: 0.43175 | val_0_logloss: 0.77112 |  0:00:02s\n",
            "epoch 4  | loss: 0.45147 | val_0_logloss: 0.67932 |  0:00:03s\n",
            "epoch 5  | loss: 0.45273 | val_0_logloss: 0.58927 |  0:00:03s\n",
            "epoch 6  | loss: 0.44501 | val_0_logloss: 0.6143  |  0:00:04s\n",
            "epoch 7  | loss: 0.42589 | val_0_logloss: 0.6851  |  0:00:05s\n",
            "epoch 8  | loss: 0.41695 | val_0_logloss: 0.72252 |  0:00:06s\n",
            "epoch 9  | loss: 0.42447 | val_0_logloss: 0.50821 |  0:00:06s\n",
            "epoch 10 | loss: 0.42429 | val_0_logloss: 1.94378 |  0:00:07s\n",
            "epoch 11 | loss: 0.4249  | val_0_logloss: 0.39179 |  0:00:08s\n",
            "epoch 12 | loss: 0.4143  | val_0_logloss: 0.42056 |  0:00:08s\n",
            "epoch 13 | loss: 0.40559 | val_0_logloss: 0.39684 |  0:00:09s\n",
            "epoch 14 | loss: 0.40324 | val_0_logloss: 0.39874 |  0:00:10s\n",
            "epoch 15 | loss: 0.42535 | val_0_logloss: 0.4063  |  0:00:10s\n",
            "epoch 16 | loss: 0.43811 | val_0_logloss: 0.44034 |  0:00:11s\n",
            "epoch 17 | loss: 0.42302 | val_0_logloss: 0.41307 |  0:00:12s\n",
            "epoch 18 | loss: 0.41371 | val_0_logloss: 0.40611 |  0:00:12s\n",
            "epoch 19 | loss: 0.41568 | val_0_logloss: 0.41126 |  0:00:13s\n",
            "epoch 20 | loss: 0.4176  | val_0_logloss: 0.43376 |  0:00:13s\n",
            "epoch 21 | loss: 0.44562 | val_0_logloss: 0.41671 |  0:00:14s\n",
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_logloss = 0.39179\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.54244 | val_0_logloss: 3.62063 |  0:00:00s\n",
            "epoch 1  | loss: 0.40226 | val_0_logloss: 0.87209 |  0:00:01s\n",
            "epoch 2  | loss: 0.3844  | val_0_logloss: 1.05656 |  0:00:01s\n",
            "epoch 3  | loss: 0.3733  | val_0_logloss: 0.57621 |  0:00:02s\n",
            "epoch 4  | loss: 0.36617 | val_0_logloss: 0.51149 |  0:00:03s\n",
            "epoch 5  | loss: 0.36196 | val_0_logloss: 0.56392 |  0:00:03s\n",
            "epoch 6  | loss: 0.37519 | val_0_logloss: 0.4979  |  0:00:04s\n",
            "epoch 7  | loss: 0.36628 | val_0_logloss: 0.45478 |  0:00:05s\n",
            "epoch 8  | loss: 0.36186 | val_0_logloss: 0.4392  |  0:00:06s\n",
            "epoch 9  | loss: 0.35553 | val_0_logloss: 0.41594 |  0:00:06s\n",
            "epoch 10 | loss: 0.35558 | val_0_logloss: 0.43044 |  0:00:07s\n",
            "epoch 11 | loss: 0.35165 | val_0_logloss: 0.38964 |  0:00:08s\n",
            "epoch 12 | loss: 0.37321 | val_0_logloss: 0.39841 |  0:00:08s\n",
            "epoch 13 | loss: 0.35906 | val_0_logloss: 0.37921 |  0:00:09s\n",
            "epoch 14 | loss: 0.35972 | val_0_logloss: 0.36515 |  0:00:10s\n",
            "epoch 15 | loss: 0.35319 | val_0_logloss: 0.36094 |  0:00:10s\n",
            "epoch 16 | loss: 0.35904 | val_0_logloss: 0.35773 |  0:00:11s\n",
            "epoch 17 | loss: 0.35579 | val_0_logloss: 0.35199 |  0:00:12s\n",
            "epoch 18 | loss: 0.35105 | val_0_logloss: 0.3381  |  0:00:12s\n",
            "epoch 19 | loss: 0.35229 | val_0_logloss: 0.34382 |  0:00:13s\n",
            "epoch 20 | loss: 0.36095 | val_0_logloss: 0.3535  |  0:00:14s\n",
            "epoch 21 | loss: 0.35977 | val_0_logloss: 0.35614 |  0:00:14s\n",
            "epoch 22 | loss: 0.36129 | val_0_logloss: 0.35531 |  0:00:15s\n",
            "epoch 23 | loss: 0.35961 | val_0_logloss: 0.34206 |  0:00:16s\n",
            "epoch 24 | loss: 0.35704 | val_0_logloss: 0.33016 |  0:00:16s\n",
            "epoch 25 | loss: 0.35046 | val_0_logloss: 0.33785 |  0:00:17s\n",
            "epoch 26 | loss: 0.34777 | val_0_logloss: 0.3381  |  0:00:18s\n",
            "epoch 27 | loss: 0.34852 | val_0_logloss: 0.33419 |  0:00:18s\n",
            "epoch 28 | loss: 0.34927 | val_0_logloss: 0.32647 |  0:00:19s\n",
            "epoch 29 | loss: 0.34955 | val_0_logloss: 0.32612 |  0:00:20s\n",
            "epoch 30 | loss: 0.35255 | val_0_logloss: 0.32731 |  0:00:20s\n",
            "epoch 31 | loss: 0.34756 | val_0_logloss: 0.33128 |  0:00:21s\n",
            "epoch 32 | loss: 0.35101 | val_0_logloss: 0.32408 |  0:00:22s\n",
            "epoch 33 | loss: 0.36001 | val_0_logloss: 0.32706 |  0:00:22s\n",
            "epoch 34 | loss: 0.35152 | val_0_logloss: 0.32875 |  0:00:23s\n",
            "epoch 35 | loss: 0.35136 | val_0_logloss: 0.33124 |  0:00:24s\n",
            "epoch 36 | loss: 0.35739 | val_0_logloss: 0.33624 |  0:00:24s\n",
            "epoch 37 | loss: 0.34805 | val_0_logloss: 0.33149 |  0:00:25s\n",
            "epoch 38 | loss: 0.35317 | val_0_logloss: 0.32758 |  0:00:26s\n",
            "epoch 39 | loss: 0.34514 | val_0_logloss: 0.32372 |  0:00:26s\n",
            "epoch 40 | loss: 0.35176 | val_0_logloss: 0.32939 |  0:00:27s\n",
            "epoch 41 | loss: 0.35091 | val_0_logloss: 0.3265  |  0:00:28s\n",
            "epoch 42 | loss: 0.35351 | val_0_logloss: 0.325   |  0:00:28s\n",
            "epoch 43 | loss: 0.35258 | val_0_logloss: 0.33558 |  0:00:29s\n",
            "epoch 44 | loss: 0.3515  | val_0_logloss: 0.33827 |  0:00:30s\n",
            "epoch 45 | loss: 0.36036 | val_0_logloss: 0.32943 |  0:00:30s\n",
            "epoch 46 | loss: 0.35058 | val_0_logloss: 0.32781 |  0:00:31s\n",
            "epoch 47 | loss: 0.35049 | val_0_logloss: 0.3281  |  0:00:32s\n",
            "epoch 48 | loss: 0.34678 | val_0_logloss: 0.32921 |  0:00:32s\n",
            "epoch 49 | loss: 0.34947 | val_0_logloss: 0.32043 |  0:00:33s\n",
            "epoch 50 | loss: 0.34801 | val_0_logloss: 0.32023 |  0:00:34s\n",
            "epoch 51 | loss: 0.34299 | val_0_logloss: 0.32224 |  0:00:35s\n",
            "epoch 52 | loss: 0.34495 | val_0_logloss: 0.32263 |  0:00:35s\n",
            "epoch 53 | loss: 0.35298 | val_0_logloss: 0.36828 |  0:00:36s\n",
            "epoch 54 | loss: 0.37566 | val_0_logloss: 0.35606 |  0:00:37s\n",
            "epoch 55 | loss: 0.36609 | val_0_logloss: 0.35171 |  0:00:37s\n",
            "epoch 56 | loss: 0.35624 | val_0_logloss: 0.34391 |  0:00:38s\n",
            "epoch 57 | loss: 0.35631 | val_0_logloss: 0.34058 |  0:00:39s\n",
            "epoch 58 | loss: 0.35319 | val_0_logloss: 0.34932 |  0:00:39s\n",
            "epoch 59 | loss: 0.35679 | val_0_logloss: 0.34212 |  0:00:40s\n",
            "epoch 60 | loss: 0.35099 | val_0_logloss: 0.33491 |  0:00:40s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_logloss = 0.32023\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.66543 | val_0_logloss: 7.27895 |  0:00:00s\n",
            "epoch 1  | loss: 0.50875 | val_0_logloss: 3.25374 |  0:00:00s\n",
            "epoch 2  | loss: 0.44726 | val_0_logloss: 4.52184 |  0:00:00s\n",
            "epoch 3  | loss: 0.4242  | val_0_logloss: 8.55342 |  0:00:00s\n",
            "epoch 4  | loss: 0.40875 | val_0_logloss: 10.50828|  0:00:00s\n",
            "epoch 5  | loss: 0.39648 | val_0_logloss: 10.58044|  0:00:01s\n",
            "epoch 6  | loss: 0.38844 | val_0_logloss: 9.00628 |  0:00:01s\n",
            "epoch 7  | loss: 0.37796 | val_0_logloss: 7.25628 |  0:00:01s\n",
            "epoch 8  | loss: 0.37027 | val_0_logloss: 4.96867 |  0:00:01s\n",
            "epoch 9  | loss: 0.3614  | val_0_logloss: 3.35933 |  0:00:01s\n",
            "epoch 10 | loss: 0.3545  | val_0_logloss: 2.17162 |  0:00:02s\n",
            "epoch 11 | loss: 0.35131 | val_0_logloss: 1.41678 |  0:00:02s\n",
            "epoch 12 | loss: 0.3468  | val_0_logloss: 1.1601  |  0:00:02s\n",
            "epoch 13 | loss: 0.34427 | val_0_logloss: 1.04371 |  0:00:02s\n",
            "epoch 14 | loss: 0.34358 | val_0_logloss: 1.03074 |  0:00:02s\n",
            "epoch 15 | loss: 0.3395  | val_0_logloss: 0.96328 |  0:00:03s\n",
            "epoch 16 | loss: 0.33428 | val_0_logloss: 0.96866 |  0:00:03s\n",
            "epoch 17 | loss: 0.33166 | val_0_logloss: 0.96322 |  0:00:03s\n",
            "epoch 18 | loss: 0.32939 | val_0_logloss: 0.91266 |  0:00:03s\n",
            "epoch 19 | loss: 0.32804 | val_0_logloss: 0.88677 |  0:00:03s\n",
            "epoch 20 | loss: 0.32878 | val_0_logloss: 0.9705  |  0:00:04s\n",
            "epoch 21 | loss: 0.32207 | val_0_logloss: 1.02157 |  0:00:04s\n",
            "epoch 22 | loss: 0.32277 | val_0_logloss: 1.12032 |  0:00:04s\n",
            "epoch 23 | loss: 0.32379 | val_0_logloss: 1.18202 |  0:00:04s\n",
            "epoch 24 | loss: 0.31911 | val_0_logloss: 1.17336 |  0:00:04s\n",
            "epoch 25 | loss: 0.31347 | val_0_logloss: 1.07872 |  0:00:04s\n",
            "epoch 26 | loss: 0.31516 | val_0_logloss: 0.98793 |  0:00:05s\n",
            "epoch 27 | loss: 0.31195 | val_0_logloss: 0.92972 |  0:00:05s\n",
            "epoch 28 | loss: 0.31246 | val_0_logloss: 0.89326 |  0:00:05s\n",
            "epoch 29 | loss: 0.31004 | val_0_logloss: 0.92621 |  0:00:05s\n",
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.88677\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 2.74567 | val_0_logloss: 13.14556|  0:00:00s\n",
            "epoch 1  | loss: 2.6956  | val_0_logloss: 9.84415 |  0:00:01s\n",
            "epoch 2  | loss: 1.77874 | val_0_logloss: 9.03965 |  0:00:01s\n",
            "epoch 3  | loss: 1.12483 | val_0_logloss: 9.19412 |  0:00:02s\n",
            "epoch 4  | loss: 0.77776 | val_0_logloss: 9.95722 |  0:00:02s\n",
            "epoch 5  | loss: 0.68938 | val_0_logloss: 8.43277 |  0:00:03s\n",
            "epoch 6  | loss: 0.75936 | val_0_logloss: 9.24614 |  0:00:03s\n",
            "epoch 7  | loss: 0.58267 | val_0_logloss: 6.17678 |  0:00:04s\n",
            "epoch 8  | loss: 0.51303 | val_0_logloss: 2.61829 |  0:00:04s\n",
            "epoch 9  | loss: 0.50548 | val_0_logloss: 4.17679 |  0:00:05s\n",
            "epoch 10 | loss: 0.46301 | val_0_logloss: 3.36087 |  0:00:05s\n",
            "epoch 11 | loss: 0.44461 | val_0_logloss: 1.66215 |  0:00:06s\n",
            "epoch 12 | loss: 0.44318 | val_0_logloss: 1.93484 |  0:00:07s\n",
            "epoch 13 | loss: 0.41177 | val_0_logloss: 2.74356 |  0:00:07s\n",
            "epoch 14 | loss: 0.40268 | val_0_logloss: 2.01125 |  0:00:08s\n",
            "epoch 15 | loss: 0.40226 | val_0_logloss: 1.57153 |  0:00:08s\n",
            "epoch 16 | loss: 0.38974 | val_0_logloss: 1.11459 |  0:00:09s\n",
            "epoch 17 | loss: 0.39581 | val_0_logloss: 1.19751 |  0:00:09s\n",
            "epoch 18 | loss: 0.38435 | val_0_logloss: 1.65459 |  0:00:10s\n",
            "epoch 19 | loss: 0.37875 | val_0_logloss: 2.31083 |  0:00:10s\n",
            "epoch 20 | loss: 0.38137 | val_0_logloss: 1.75099 |  0:00:11s\n",
            "epoch 21 | loss: 0.37554 | val_0_logloss: 1.39838 |  0:00:11s\n",
            "epoch 22 | loss: 0.37507 | val_0_logloss: 1.30815 |  0:00:12s\n",
            "epoch 23 | loss: 0.37139 | val_0_logloss: 1.23834 |  0:00:12s\n",
            "epoch 24 | loss: 0.3657  | val_0_logloss: 1.19567 |  0:00:13s\n",
            "epoch 25 | loss: 0.36178 | val_0_logloss: 1.27948 |  0:00:14s\n",
            "epoch 26 | loss: 0.35778 | val_0_logloss: 1.18659 |  0:00:14s\n",
            "\n",
            "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_logloss = 1.11459\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 19.5789 | val_0_logloss: 11.41994|  0:00:01s\n",
            "epoch 1  | loss: 1.16939 | val_0_logloss: 6.63984 |  0:00:02s\n",
            "epoch 2  | loss: 0.67204 | val_0_logloss: 2.7004  |  0:00:03s\n",
            "epoch 3  | loss: 0.48992 | val_0_logloss: 2.18342 |  0:00:04s\n",
            "epoch 4  | loss: 0.46163 | val_0_logloss: 1.09118 |  0:00:05s\n",
            "epoch 5  | loss: 0.43895 | val_0_logloss: 1.05681 |  0:00:06s\n",
            "epoch 6  | loss: 0.45009 | val_0_logloss: 0.65089 |  0:00:08s\n",
            "epoch 7  | loss: 0.42865 | val_0_logloss: 0.59081 |  0:00:09s\n",
            "epoch 8  | loss: 0.42564 | val_0_logloss: 0.56277 |  0:00:10s\n",
            "epoch 9  | loss: 0.43937 | val_0_logloss: 0.58643 |  0:00:11s\n",
            "epoch 10 | loss: 0.53817 | val_0_logloss: 0.52741 |  0:00:12s\n",
            "epoch 11 | loss: 0.43102 | val_0_logloss: 0.46335 |  0:00:13s\n",
            "epoch 12 | loss: 0.45286 | val_0_logloss: 0.47299 |  0:00:14s\n",
            "epoch 13 | loss: 0.44312 | val_0_logloss: 0.44904 |  0:00:16s\n",
            "epoch 14 | loss: 0.46326 | val_0_logloss: 0.43528 |  0:00:17s\n",
            "epoch 15 | loss: 0.45594 | val_0_logloss: 0.4223  |  0:00:18s\n",
            "epoch 16 | loss: 0.43434 | val_0_logloss: 0.42789 |  0:00:19s\n",
            "epoch 17 | loss: 0.4352  | val_0_logloss: 0.4167  |  0:00:20s\n",
            "epoch 18 | loss: 0.42549 | val_0_logloss: 0.4237  |  0:00:21s\n",
            "epoch 19 | loss: 0.43095 | val_0_logloss: 0.42064 |  0:00:22s\n",
            "epoch 20 | loss: 0.43232 | val_0_logloss: 0.48066 |  0:00:23s\n",
            "epoch 21 | loss: 0.43125 | val_0_logloss: 0.44125 |  0:00:25s\n",
            "epoch 22 | loss: 0.43891 | val_0_logloss: 0.43468 |  0:00:26s\n",
            "epoch 23 | loss: 0.43657 | val_0_logloss: 0.67374 |  0:00:27s\n",
            "epoch 24 | loss: 0.49642 | val_0_logloss: 0.47766 |  0:00:28s\n",
            "epoch 25 | loss: 0.49431 | val_0_logloss: 0.52752 |  0:00:29s\n",
            "epoch 26 | loss: 0.50988 | val_0_logloss: 0.58277 |  0:00:30s\n",
            "epoch 27 | loss: 0.93006 | val_0_logloss: 0.98535 |  0:00:31s\n",
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.4167\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 3.31173 | val_0_logloss: 7.38442 |  0:00:00s\n",
            "epoch 1  | loss: 2.2553  | val_0_logloss: 6.38398 |  0:00:01s\n",
            "epoch 2  | loss: 0.96955 | val_0_logloss: 21.90433|  0:00:01s\n",
            "epoch 3  | loss: 0.77562 | val_0_logloss: 6.59431 |  0:00:02s\n",
            "epoch 4  | loss: 0.60061 | val_0_logloss: 3.35841 |  0:00:02s\n",
            "epoch 5  | loss: 0.7503  | val_0_logloss: 5.09772 |  0:00:03s\n",
            "epoch 6  | loss: 0.58144 | val_0_logloss: 2.9329  |  0:00:04s\n",
            "epoch 7  | loss: 0.55787 | val_0_logloss: 3.19177 |  0:00:04s\n",
            "epoch 8  | loss: 0.48339 | val_0_logloss: 0.70373 |  0:00:05s\n",
            "epoch 9  | loss: 0.49016 | val_0_logloss: 0.94471 |  0:00:05s\n",
            "epoch 10 | loss: 0.44693 | val_0_logloss: 1.42292 |  0:00:06s\n",
            "epoch 11 | loss: 0.45314 | val_0_logloss: 2.00184 |  0:00:07s\n",
            "epoch 12 | loss: 0.42624 | val_0_logloss: 1.76596 |  0:00:07s\n",
            "epoch 13 | loss: 0.42595 | val_0_logloss: 2.25014 |  0:00:08s\n",
            "epoch 14 | loss: 0.41211 | val_0_logloss: 2.31639 |  0:00:08s\n",
            "epoch 15 | loss: 0.40674 | val_0_logloss: 1.43952 |  0:00:09s\n",
            "epoch 16 | loss: 0.39949 | val_0_logloss: 1.4995  |  0:00:09s\n",
            "epoch 17 | loss: 0.40035 | val_0_logloss: 1.85719 |  0:00:10s\n",
            "epoch 18 | loss: 0.39236 | val_0_logloss: 1.31276 |  0:00:11s\n",
            "\n",
            "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_logloss = 0.70373\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.78163 | val_0_logloss: 12.17895|  0:00:01s\n",
            "epoch 1  | loss: 0.48152 | val_0_logloss: 3.77897 |  0:00:02s\n",
            "epoch 2  | loss: 0.46299 | val_0_logloss: 2.16536 |  0:00:03s\n",
            "epoch 3  | loss: 0.4191  | val_0_logloss: 1.639   |  0:00:05s\n",
            "epoch 4  | loss: 0.40947 | val_0_logloss: 0.78203 |  0:00:06s\n",
            "epoch 5  | loss: 0.39088 | val_0_logloss: 0.63263 |  0:00:07s\n",
            "epoch 6  | loss: 0.38    | val_0_logloss: 0.68509 |  0:00:09s\n",
            "epoch 7  | loss: 0.36881 | val_0_logloss: 0.49897 |  0:00:10s\n",
            "epoch 8  | loss: 0.36188 | val_0_logloss: 0.48098 |  0:00:11s\n",
            "epoch 9  | loss: 0.36462 | val_0_logloss: 0.48196 |  0:00:12s\n",
            "epoch 10 | loss: 0.35823 | val_0_logloss: 0.39673 |  0:00:14s\n",
            "epoch 11 | loss: 0.35961 | val_0_logloss: 0.40656 |  0:00:15s\n",
            "epoch 12 | loss: 0.36426 | val_0_logloss: 0.38139 |  0:00:16s\n",
            "epoch 13 | loss: 0.3508  | val_0_logloss: 0.35584 |  0:00:17s\n",
            "epoch 14 | loss: 0.35504 | val_0_logloss: 0.36548 |  0:00:19s\n",
            "epoch 15 | loss: 0.35652 | val_0_logloss: 0.35616 |  0:00:20s\n",
            "epoch 16 | loss: 0.36069 | val_0_logloss: 0.34355 |  0:00:21s\n",
            "epoch 17 | loss: 0.34991 | val_0_logloss: 0.34108 |  0:00:23s\n",
            "epoch 18 | loss: 0.35302 | val_0_logloss: 0.34063 |  0:00:24s\n",
            "epoch 19 | loss: 0.34548 | val_0_logloss: 0.33419 |  0:00:25s\n",
            "epoch 20 | loss: 0.34844 | val_0_logloss: 0.34434 |  0:00:27s\n",
            "epoch 21 | loss: 0.34803 | val_0_logloss: 0.33093 |  0:00:28s\n",
            "epoch 22 | loss: 0.35368 | val_0_logloss: 0.34418 |  0:00:29s\n",
            "epoch 23 | loss: 0.35013 | val_0_logloss: 0.35248 |  0:00:30s\n",
            "epoch 24 | loss: 0.35027 | val_0_logloss: 0.32994 |  0:00:32s\n",
            "epoch 25 | loss: 0.35221 | val_0_logloss: 0.32205 |  0:00:33s\n",
            "epoch 26 | loss: 0.3471  | val_0_logloss: 0.33995 |  0:00:34s\n",
            "epoch 27 | loss: 0.34308 | val_0_logloss: 0.33555 |  0:00:35s\n",
            "epoch 28 | loss: 0.34997 | val_0_logloss: 0.33636 |  0:00:37s\n",
            "epoch 29 | loss: 0.34028 | val_0_logloss: 0.33056 |  0:00:38s\n",
            "epoch 30 | loss: 0.33822 | val_0_logloss: 0.33274 |  0:00:39s\n",
            "epoch 31 | loss: 0.34142 | val_0_logloss: 0.32613 |  0:00:40s\n",
            "epoch 32 | loss: 0.34774 | val_0_logloss: 0.32925 |  0:00:42s\n",
            "epoch 33 | loss: 0.34809 | val_0_logloss: 0.33118 |  0:00:43s\n",
            "epoch 34 | loss: 0.34149 | val_0_logloss: 0.32781 |  0:00:44s\n",
            "epoch 35 | loss: 0.34203 | val_0_logloss: 0.33844 |  0:00:45s\n",
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_logloss = 0.32205\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.70165 | val_0_logloss: 2.469   |  0:00:01s\n",
            "epoch 1  | loss: 0.4171  | val_0_logloss: 3.01514 |  0:00:02s\n",
            "epoch 2  | loss: 0.40111 | val_0_logloss: 0.88182 |  0:00:03s\n",
            "epoch 3  | loss: 0.38686 | val_0_logloss: 1.0809  |  0:00:04s\n",
            "epoch 4  | loss: 0.36489 | val_0_logloss: 0.70463 |  0:00:05s\n",
            "epoch 5  | loss: 0.35623 | val_0_logloss: 0.68079 |  0:00:06s\n",
            "epoch 6  | loss: 0.35406 | val_0_logloss: 0.62304 |  0:00:07s\n",
            "epoch 7  | loss: 0.34953 | val_0_logloss: 0.56472 |  0:00:08s\n",
            "epoch 8  | loss: 0.35473 | val_0_logloss: 0.49148 |  0:00:10s\n",
            "epoch 9  | loss: 0.34656 | val_0_logloss: 0.46911 |  0:00:11s\n",
            "epoch 10 | loss: 0.3412  | val_0_logloss: 0.45142 |  0:00:12s\n",
            "epoch 11 | loss: 0.33956 | val_0_logloss: 0.35024 |  0:00:13s\n",
            "epoch 12 | loss: 0.34089 | val_0_logloss: 0.40366 |  0:00:14s\n",
            "epoch 13 | loss: 0.3483  | val_0_logloss: 0.36438 |  0:00:15s\n",
            "epoch 14 | loss: 0.34671 | val_0_logloss: 0.34804 |  0:00:16s\n",
            "epoch 15 | loss: 0.33942 | val_0_logloss: 0.32916 |  0:00:18s\n",
            "epoch 16 | loss: 0.33632 | val_0_logloss: 0.33491 |  0:00:19s\n",
            "epoch 17 | loss: 0.33856 | val_0_logloss: 0.31773 |  0:00:20s\n",
            "epoch 18 | loss: 0.3376  | val_0_logloss: 0.32482 |  0:00:21s\n",
            "epoch 19 | loss: 0.33964 | val_0_logloss: 0.31832 |  0:00:22s\n",
            "epoch 20 | loss: 0.33618 | val_0_logloss: 0.31712 |  0:00:23s\n",
            "epoch 21 | loss: 0.3369  | val_0_logloss: 0.32288 |  0:00:24s\n",
            "epoch 22 | loss: 0.34218 | val_0_logloss: 0.32722 |  0:00:25s\n",
            "epoch 23 | loss: 0.33279 | val_0_logloss: 0.30893 |  0:00:27s\n",
            "epoch 24 | loss: 0.33004 | val_0_logloss: 0.30753 |  0:00:28s\n",
            "epoch 25 | loss: 0.33801 | val_0_logloss: 0.32544 |  0:00:29s\n",
            "epoch 26 | loss: 0.33514 | val_0_logloss: 0.31494 |  0:00:30s\n",
            "epoch 27 | loss: 0.33374 | val_0_logloss: 0.30937 |  0:00:31s\n",
            "epoch 28 | loss: 0.33745 | val_0_logloss: 0.30382 |  0:00:32s\n",
            "epoch 29 | loss: 0.3281  | val_0_logloss: 0.30587 |  0:00:33s\n",
            "epoch 30 | loss: 0.33876 | val_0_logloss: 0.30351 |  0:00:34s\n",
            "epoch 31 | loss: 0.33293 | val_0_logloss: 0.32292 |  0:00:36s\n",
            "epoch 32 | loss: 0.33309 | val_0_logloss: 0.32966 |  0:00:37s\n",
            "epoch 33 | loss: 0.33744 | val_0_logloss: 0.31527 |  0:00:38s\n",
            "epoch 34 | loss: 0.33747 | val_0_logloss: 0.31881 |  0:00:39s\n",
            "epoch 35 | loss: 0.32515 | val_0_logloss: 0.31173 |  0:00:40s\n",
            "epoch 36 | loss: 0.33084 | val_0_logloss: 0.31754 |  0:00:41s\n",
            "epoch 37 | loss: 0.33656 | val_0_logloss: 0.32867 |  0:00:42s\n",
            "epoch 38 | loss: 0.33777 | val_0_logloss: 0.31641 |  0:00:43s\n",
            "epoch 39 | loss: 0.33238 | val_0_logloss: 0.30015 |  0:00:44s\n",
            "epoch 40 | loss: 0.33202 | val_0_logloss: 0.30806 |  0:00:46s\n",
            "epoch 41 | loss: 0.3262  | val_0_logloss: 0.30956 |  0:00:47s\n",
            "epoch 42 | loss: 0.33371 | val_0_logloss: 0.31525 |  0:00:48s\n",
            "epoch 43 | loss: 0.32659 | val_0_logloss: 0.31037 |  0:00:49s\n",
            "epoch 44 | loss: 0.32629 | val_0_logloss: 0.30636 |  0:00:50s\n",
            "epoch 45 | loss: 0.32469 | val_0_logloss: 0.30219 |  0:00:51s\n",
            "epoch 46 | loss: 0.32251 | val_0_logloss: 0.31394 |  0:00:52s\n",
            "epoch 47 | loss: 0.33211 | val_0_logloss: 0.31341 |  0:00:53s\n",
            "epoch 48 | loss: 0.32504 | val_0_logloss: 0.31724 |  0:00:55s\n",
            "epoch 49 | loss: 0.32364 | val_0_logloss: 0.31156 |  0:00:56s\n",
            "\n",
            "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_logloss = 0.30015\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 0.75711 | val_0_logloss: 12.11827|  0:00:00s\n",
            "epoch 1  | loss: 0.55126 | val_0_logloss: 2.62521 |  0:00:01s\n",
            "epoch 2  | loss: 0.45981 | val_0_logloss: 2.9373  |  0:00:01s\n",
            "epoch 3  | loss: 0.43153 | val_0_logloss: 1.5322  |  0:00:02s\n",
            "epoch 4  | loss: 0.4385  | val_0_logloss: 0.96365 |  0:00:02s\n",
            "epoch 5  | loss: 0.39661 | val_0_logloss: 0.78312 |  0:00:03s\n",
            "epoch 6  | loss: 0.38966 | val_0_logloss: 0.69031 |  0:00:04s\n",
            "epoch 7  | loss: 0.3792  | val_0_logloss: 0.56681 |  0:00:04s\n",
            "epoch 8  | loss: 0.38602 | val_0_logloss: 0.59939 |  0:00:05s\n",
            "epoch 9  | loss: 0.3899  | val_0_logloss: 0.6282  |  0:00:05s\n",
            "epoch 10 | loss: 0.37481 | val_0_logloss: 0.65368 |  0:00:06s\n",
            "epoch 11 | loss: 0.37577 | val_0_logloss: 0.60005 |  0:00:07s\n",
            "epoch 12 | loss: 0.36657 | val_0_logloss: 0.58554 |  0:00:07s\n",
            "epoch 13 | loss: 0.37213 | val_0_logloss: 0.57397 |  0:00:08s\n",
            "epoch 14 | loss: 0.36069 | val_0_logloss: 0.50664 |  0:00:08s\n",
            "epoch 15 | loss: 0.37471 | val_0_logloss: 0.44341 |  0:00:09s\n",
            "epoch 16 | loss: 0.3643  | val_0_logloss: 0.55478 |  0:00:09s\n",
            "epoch 17 | loss: 0.35822 | val_0_logloss: 0.46527 |  0:00:10s\n",
            "epoch 18 | loss: 0.36209 | val_0_logloss: 0.45665 |  0:00:11s\n",
            "epoch 19 | loss: 0.35737 | val_0_logloss: 0.43222 |  0:00:11s\n",
            "epoch 20 | loss: 0.36985 | val_0_logloss: 0.41444 |  0:00:12s\n",
            "epoch 21 | loss: 0.3664  | val_0_logloss: 0.41853 |  0:00:12s\n",
            "epoch 22 | loss: 0.36995 | val_0_logloss: 0.38716 |  0:00:13s\n",
            "epoch 23 | loss: 0.36763 | val_0_logloss: 0.37713 |  0:00:13s\n",
            "epoch 24 | loss: 0.36028 | val_0_logloss: 0.35971 |  0:00:14s\n",
            "epoch 25 | loss: 0.3559  | val_0_logloss: 0.37567 |  0:00:15s\n",
            "epoch 26 | loss: 0.35355 | val_0_logloss: 0.38074 |  0:00:15s\n",
            "epoch 27 | loss: 0.3509  | val_0_logloss: 0.3513  |  0:00:16s\n",
            "epoch 28 | loss: 0.34883 | val_0_logloss: 0.35166 |  0:00:17s\n",
            "epoch 29 | loss: 0.35587 | val_0_logloss: 0.35918 |  0:00:17s\n",
            "epoch 30 | loss: 0.36428 | val_0_logloss: 0.34515 |  0:00:18s\n",
            "epoch 31 | loss: 0.36013 | val_0_logloss: 0.33117 |  0:00:18s\n",
            "epoch 32 | loss: 0.35973 | val_0_logloss: 0.3801  |  0:00:19s\n",
            "epoch 33 | loss: 0.38135 | val_0_logloss: 0.37865 |  0:00:19s\n",
            "epoch 34 | loss: 0.36601 | val_0_logloss: 0.36354 |  0:00:20s\n",
            "epoch 35 | loss: 0.36421 | val_0_logloss: 0.34184 |  0:00:21s\n",
            "epoch 36 | loss: 0.36447 | val_0_logloss: 0.34768 |  0:00:21s\n",
            "epoch 37 | loss: 0.36155 | val_0_logloss: 0.34315 |  0:00:22s\n",
            "epoch 38 | loss: 0.35915 | val_0_logloss: 0.35051 |  0:00:22s\n",
            "epoch 39 | loss: 0.35577 | val_0_logloss: 0.33218 |  0:00:23s\n",
            "epoch 40 | loss: 0.35248 | val_0_logloss: 0.33898 |  0:00:23s\n",
            "epoch 41 | loss: 0.35119 | val_0_logloss: 0.34338 |  0:00:24s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_logloss = 0.33117\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 3.22357 | val_0_logloss: 18.69054|  0:00:00s\n",
            "epoch 1  | loss: 0.81361 | val_0_logloss: 2.88332 |  0:00:01s\n",
            "epoch 2  | loss: 0.45535 | val_0_logloss: 3.08939 |  0:00:02s\n",
            "epoch 3  | loss: 0.39218 | val_0_logloss: 2.18558 |  0:00:03s\n",
            "epoch 4  | loss: 0.36878 | val_0_logloss: 0.65035 |  0:00:03s\n",
            "epoch 5  | loss: 0.35766 | val_0_logloss: 1.19232 |  0:00:04s\n",
            "epoch 6  | loss: 0.34833 | val_0_logloss: 1.06562 |  0:00:05s\n",
            "epoch 7  | loss: 0.34309 | val_0_logloss: 1.03315 |  0:00:06s\n",
            "epoch 8  | loss: 0.33633 | val_0_logloss: 1.09412 |  0:00:07s\n",
            "epoch 9  | loss: 0.33609 | val_0_logloss: 1.08691 |  0:00:07s\n",
            "epoch 10 | loss: 0.32899 | val_0_logloss: 1.14763 |  0:00:08s\n",
            "epoch 11 | loss: 0.32712 | val_0_logloss: 1.08293 |  0:00:09s\n",
            "epoch 12 | loss: 0.32228 | val_0_logloss: 1.43891 |  0:00:10s\n",
            "epoch 13 | loss: 0.31782 | val_0_logloss: 1.18635 |  0:00:10s\n",
            "epoch 14 | loss: 0.31988 | val_0_logloss: 1.06615 |  0:00:11s\n",
            "\n",
            "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_logloss = 0.65035\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 5.61198 | val_0_logloss: 7.30573 |  0:00:00s\n",
            "epoch 1  | loss: 1.44752 | val_0_logloss: 8.47846 |  0:00:01s\n",
            "epoch 2  | loss: 0.50637 | val_0_logloss: 5.82395 |  0:00:01s\n",
            "epoch 3  | loss: 0.46417 | val_0_logloss: 2.83475 |  0:00:02s\n",
            "epoch 4  | loss: 0.59106 | val_0_logloss: 1.63168 |  0:00:02s\n",
            "epoch 5  | loss: 0.45948 | val_0_logloss: 1.99272 |  0:00:03s\n",
            "epoch 6  | loss: 0.45609 | val_0_logloss: 1.47174 |  0:00:03s\n",
            "epoch 7  | loss: 0.44551 | val_0_logloss: 1.52338 |  0:00:04s\n",
            "epoch 8  | loss: 0.43442 | val_0_logloss: 1.58839 |  0:00:04s\n",
            "epoch 9  | loss: 0.43863 | val_0_logloss: 1.55035 |  0:00:05s\n",
            "epoch 10 | loss: 0.44474 | val_0_logloss: 1.75435 |  0:00:05s\n",
            "epoch 11 | loss: 0.45195 | val_0_logloss: 0.84897 |  0:00:06s\n",
            "epoch 12 | loss: 0.45192 | val_0_logloss: 0.63512 |  0:00:06s\n",
            "epoch 13 | loss: 0.44821 | val_0_logloss: 0.64859 |  0:00:07s\n",
            "epoch 14 | loss: 0.4496  | val_0_logloss: 1.113   |  0:00:07s\n",
            "epoch 15 | loss: 0.45428 | val_0_logloss: 1.2634  |  0:00:08s\n",
            "epoch 16 | loss: 0.45389 | val_0_logloss: 1.37429 |  0:00:08s\n",
            "epoch 17 | loss: 0.46316 | val_0_logloss: 0.70554 |  0:00:09s\n",
            "epoch 18 | loss: 0.44757 | val_0_logloss: 0.61054 |  0:00:10s\n",
            "epoch 19 | loss: 0.44541 | val_0_logloss: 0.7004  |  0:00:10s\n",
            "epoch 20 | loss: 0.43884 | val_0_logloss: 1.10231 |  0:00:11s\n",
            "epoch 21 | loss: 0.43557 | val_0_logloss: 1.48481 |  0:00:11s\n",
            "epoch 22 | loss: 0.4422  | val_0_logloss: 1.53485 |  0:00:12s\n",
            "epoch 23 | loss: 0.44322 | val_0_logloss: 1.03803 |  0:00:12s\n",
            "epoch 24 | loss: 0.44386 | val_0_logloss: 0.80704 |  0:00:13s\n",
            "epoch 25 | loss: 0.44463 | val_0_logloss: 0.96014 |  0:00:13s\n",
            "epoch 26 | loss: 0.44131 | val_0_logloss: 0.99313 |  0:00:14s\n",
            "epoch 27 | loss: 0.44596 | val_0_logloss: 0.82584 |  0:00:14s\n",
            "epoch 28 | loss: 0.44652 | val_0_logloss: 0.85066 |  0:00:15s\n",
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_logloss = 0.61054\n",
            "Best weights from best epoch are automatically used!\n",
            "100%|██████████| 15/15 [07:06<00:00, 28.40s/it, best loss: 0.3001489310544985]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1=hyperopt.pyll.stochastic.sample(reg_params)\n",
        "print(a1)\n",
        "# tb_ll_cv(a1)\n",
        "# #torch.from_numpy(a1['gamma']).dtype"
      ],
      "metadata": {
        "id": "vUU6eKo6dNnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582dfc66-b60a-4ec0-a53c-57286a49cd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 512, 'gamma': 1.6867551228669113, 'lr': 0.952292858193817, 'momentum': 0.03044791321571015, 'n_a': 21.0, 'n_steps': 7.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMQslGVyQW2m",
        "outputId": "527cd610-b826-4d88-ee64-b3b2a5cc4d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 0,\n",
              " 'feature_dim': 27.0,\n",
              " 'learning_rate': 0.04732037402888312,\n",
              " 'momentum': 0.28382137773095045,\n",
              " 'n_steps': 6.0,\n",
              " 'relaxation_factor': 0.9003863490475343}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_list=[512, 1024, 2048, 4096, 8192]"
      ],
      "metadata": {
        "id": "CRuEfrZy99AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=TabNetClassifier(n_a=int(best['feature_dim']), n_d=int(best['feature_dim']), n_steps=int(best['n_steps']), momentum=best['momentum'], gamma=best['relaxation_factor'], optimizer_params=dict(lr=best['learning_rate']), device_name='cuda')\n",
        "model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], batch_size=batch_size_list[best['batch_size']],max_epochs=100,eval_metric=['logloss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcJzGQ03SQ6u",
        "outputId": "bc787130-2237-48d0-ebfd-454192b260fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 0.70165 | val_0_logloss: 2.469   |  0:00:01s\n",
            "epoch 1  | loss: 0.4171  | val_0_logloss: 3.01514 |  0:00:02s\n",
            "epoch 2  | loss: 0.40111 | val_0_logloss: 0.88182 |  0:00:03s\n",
            "epoch 3  | loss: 0.38686 | val_0_logloss: 1.0809  |  0:00:04s\n",
            "epoch 4  | loss: 0.36489 | val_0_logloss: 0.70463 |  0:00:05s\n",
            "epoch 5  | loss: 0.35623 | val_0_logloss: 0.68079 |  0:00:06s\n",
            "epoch 6  | loss: 0.35406 | val_0_logloss: 0.62304 |  0:00:07s\n",
            "epoch 7  | loss: 0.34953 | val_0_logloss: 0.56472 |  0:00:08s\n",
            "epoch 8  | loss: 0.35473 | val_0_logloss: 0.49148 |  0:00:10s\n",
            "epoch 9  | loss: 0.34656 | val_0_logloss: 0.46911 |  0:00:11s\n",
            "epoch 10 | loss: 0.3412  | val_0_logloss: 0.45142 |  0:00:12s\n",
            "epoch 11 | loss: 0.33956 | val_0_logloss: 0.35024 |  0:00:13s\n",
            "epoch 12 | loss: 0.34089 | val_0_logloss: 0.40366 |  0:00:14s\n",
            "epoch 13 | loss: 0.3483  | val_0_logloss: 0.36438 |  0:00:15s\n",
            "epoch 14 | loss: 0.34671 | val_0_logloss: 0.34804 |  0:00:16s\n",
            "epoch 15 | loss: 0.33942 | val_0_logloss: 0.32916 |  0:00:17s\n",
            "epoch 16 | loss: 0.33632 | val_0_logloss: 0.33491 |  0:00:18s\n",
            "epoch 17 | loss: 0.33856 | val_0_logloss: 0.31773 |  0:00:20s\n",
            "epoch 18 | loss: 0.3376  | val_0_logloss: 0.32482 |  0:00:21s\n",
            "epoch 19 | loss: 0.33964 | val_0_logloss: 0.31832 |  0:00:22s\n",
            "epoch 20 | loss: 0.33618 | val_0_logloss: 0.31712 |  0:00:23s\n",
            "epoch 21 | loss: 0.3369  | val_0_logloss: 0.32288 |  0:00:24s\n",
            "epoch 22 | loss: 0.34218 | val_0_logloss: 0.32722 |  0:00:25s\n",
            "epoch 23 | loss: 0.33279 | val_0_logloss: 0.30893 |  0:00:26s\n",
            "epoch 24 | loss: 0.33004 | val_0_logloss: 0.30753 |  0:00:27s\n",
            "epoch 25 | loss: 0.33801 | val_0_logloss: 0.32544 |  0:00:29s\n",
            "epoch 26 | loss: 0.33514 | val_0_logloss: 0.31494 |  0:00:30s\n",
            "epoch 27 | loss: 0.33374 | val_0_logloss: 0.30937 |  0:00:31s\n",
            "epoch 28 | loss: 0.33745 | val_0_logloss: 0.30382 |  0:00:32s\n",
            "epoch 29 | loss: 0.3281  | val_0_logloss: 0.30587 |  0:00:33s\n",
            "epoch 30 | loss: 0.33876 | val_0_logloss: 0.30351 |  0:00:34s\n",
            "epoch 31 | loss: 0.33293 | val_0_logloss: 0.32292 |  0:00:35s\n",
            "epoch 32 | loss: 0.33309 | val_0_logloss: 0.32966 |  0:00:36s\n",
            "epoch 33 | loss: 0.33744 | val_0_logloss: 0.31527 |  0:00:37s\n",
            "epoch 34 | loss: 0.33747 | val_0_logloss: 0.31881 |  0:00:39s\n",
            "epoch 35 | loss: 0.32515 | val_0_logloss: 0.31173 |  0:00:40s\n",
            "epoch 36 | loss: 0.33084 | val_0_logloss: 0.31754 |  0:00:41s\n",
            "epoch 37 | loss: 0.33656 | val_0_logloss: 0.32867 |  0:00:42s\n",
            "epoch 38 | loss: 0.33777 | val_0_logloss: 0.31641 |  0:00:43s\n",
            "epoch 39 | loss: 0.33238 | val_0_logloss: 0.30015 |  0:00:44s\n",
            "epoch 40 | loss: 0.33202 | val_0_logloss: 0.30806 |  0:00:45s\n",
            "epoch 41 | loss: 0.3262  | val_0_logloss: 0.30956 |  0:00:46s\n",
            "epoch 42 | loss: 0.33371 | val_0_logloss: 0.31525 |  0:00:47s\n",
            "epoch 43 | loss: 0.32659 | val_0_logloss: 0.31037 |  0:00:48s\n",
            "epoch 44 | loss: 0.32629 | val_0_logloss: 0.30636 |  0:00:50s\n",
            "epoch 45 | loss: 0.32469 | val_0_logloss: 0.30219 |  0:00:51s\n",
            "epoch 46 | loss: 0.32251 | val_0_logloss: 0.31394 |  0:00:52s\n",
            "epoch 47 | loss: 0.33211 | val_0_logloss: 0.31341 |  0:00:53s\n",
            "epoch 48 | loss: 0.32504 | val_0_logloss: 0.31724 |  0:00:54s\n",
            "epoch 49 | loss: 0.32364 | val_0_logloss: 0.31156 |  0:00:55s\n",
            "\n",
            "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_logloss = 0.30015\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "loss1 = criterion(torch.from_numpy(model.predict_proba(x_test)),torch.from_numpy(y_test))\n",
        "print(loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY5D2n3Hmkd7",
        "outputId": "fea5b892-76ef-4e09-88b0-34f843b77af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4686)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in torch.from_numpy(model.predict_proba(x_test)):\n",
        "  l.append(i[0])\n",
        "b=torch.FloatTensor(l)"
      ],
      "metadata": {
        "id": "29OakR_VDJgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "loss1 = criterion(1-b,torch.from_numpy(y_test).float())\n",
        "print(loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YLcDRp4EfEl",
        "outputId": "6e96abfd-b9f8-49d6-c8eb-5403d277faed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3552)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=model.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "Fu5oeamHps9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(a).to_csv(\"data_preds.csv\")"
      ],
      "metadata": {
        "id": "BsAtC5HLpw3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErIdUijWp1L4",
        "outputId": "10ff2c2d-e86c-4664-b056-c6bc9e9e0790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_preds.csv\tsample_data  test_shrutime.csv\ttrain_shrutime.csv\n"
          ]
        }
      ]
    }
  ]
}